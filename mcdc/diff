diff --git a/mcdc/card.py b/mcdc/card.py
index bec9298..7548b58 100644
--- a/mcdc/card.py
+++ b/mcdc/card.py
@@ -24,14 +24,6 @@ class InputDeck:
 
         self.tally = {
             "tag": "Tally",
-            "tracklength": True,
-            "flux": False,
-            "density": False,
-            "fission": False,
-            "total": False,
-            "current": False,
-            "eddington": False,
-            "exit": False,
             "mesh": make_card_mesh(),
         }
 
diff --git a/mcdc/constant.py b/mcdc/constant.py
index 431d123..8ab6824 100644
--- a/mcdc/constant.py
+++ b/mcdc/constant.py
@@ -16,6 +16,14 @@ EVENT_LATTICE = 1 << 8
 EVENT_SURFACE_MOVE = 1 << 9
 EVENT_DOMAIN = 1 << 10
 
+# Data index
+TALLY = 0
+
+# Tally bins
+TALLY_SCORE = 0
+TALLY_SUM = 1
+TALLY_SUM_SQ = 2
+
 # Gyration raius type
 GYRATION_RADIUS_ALL = 0
 GYRATION_RADIUS_INFINITE_X = 1
diff --git a/mcdc/input_.py b/mcdc/input_.py
index 2bc1fd5..e6b73c3 100644
--- a/mcdc/input_.py
+++ b/mcdc/input_.py
@@ -915,18 +915,6 @@ def tally(
     if mcdc.input_deck.setting["mode_CE"]:
         card["mesh"]["g"] = E
 
-    # Set score flags
-    for s in scores:
-        found = False
-        for score_name in type_.score_list:
-            if s.replace("-", "_") == score_name:
-                card["tracklength"] = True
-                card[score_name] = True
-                found = True
-                break
-        if not found:
-            print_error("Unknown tally score %s" % s)
-
     return card
 
 
diff --git a/mcdc/kernel.py b/mcdc/kernel.py
index f5fb68b..9aea60c 100644
--- a/mcdc/kernel.py
+++ b/mcdc/kernel.py
@@ -8,7 +8,7 @@ import mcdc.type_ as type_
 
 from mcdc.constant import *
 from mcdc.print_ import print_error, print_msg
-from mcdc.type_ import score_list, iqmc_score_list
+from mcdc.type_ import iqmc_score_list
 from mcdc.loop import loop_source
 
 
@@ -1556,14 +1556,6 @@ def surface_bc(P, surface, trans):
         surface_reflect(P, surface, trans)
 
 
-@njit
-def surface_exit_evaluate(P):
-    if P["surface_ID"] == 0:
-        return 0
-    else:
-        return 1
-
-
 @njit
 def surface_reflect(P, surface, trans):
     ux = P["ux"]
@@ -1820,11 +1812,11 @@ def mesh_get_angular_index(P, mesh):
 
 
 @njit
-def mesh_get_energy_index(P, mesh, mcdc):
+def mesh_get_energy_index(P, mesh, mode_MG):
     # Check if outside grid
     outside = False
 
-    if mcdc["setting"]["mode_MG"]:
+    if mode_MG:
         return binary_search(P["g"], mesh["g"]), outside
     else:
         E = P["E"]
@@ -1877,106 +1869,72 @@ def mesh_crossing_evaluate(P, mesh):
 
 
 @njit
-def score_tracklength(P, distance, mcdc):
-    tally = mcdc["tally"]
+def score_tracklength(P, distance, data, mcdc):
+    tally = data[TALLY]
     material = mcdc["materials"][P["material_ID"]]
+    mesh = mcdc["tally"]["mesh"]
+    stride = mcdc["tally"]["stride"]
 
     # Get indices
     s = P["sensitivity_ID"]
-    t, x, y, z, outside = mesh_get_index(P, tally["mesh"])
-    mu, azi = mesh_get_angular_index(P, tally["mesh"])
-    g, outside_energy = mesh_get_energy_index(P, tally["mesh"], mcdc)
+    it, ix, iy, iz, outside = mesh_get_index(P, mesh)
+    mu, azi = mesh_get_angular_index(P, mesh)
+    g, outside_energy = mesh_get_energy_index(P, mesh, mcdc["setting"]["mode_MG"])
 
     # Outside grid?
     if outside or outside_energy:
         return
 
-    # Score
-    flux = distance * P["w"]
-    if tally["flux"]:
-        score_flux(s, g, t, x, y, z, mu, azi, flux, tally["score"]["flux"])
-    if tally["density"]:
-        flux /= get_particle_speed(P, mcdc)
-        score_flux(s, g, t, x, y, z, mu, azi, flux, tally["score"]["density"])
-    if tally["fission"]:
-        flux *= get_MacroXS(XS_FISSION, material, P, mcdc)
-        score_flux(s, g, t, x, y, z, mu, azi, flux, tally["score"]["fission"])
-    if tally["total"]:
-        flux *= get_MacroXS(XS_TOTAL, material, P, mcdc)
-        score_flux(s, g, t, x, y, z, mu, azi, flux, tally["score"]["total"])
-    if tally["current"]:
-        score_current(s, g, t, x, y, z, flux, P, tally["score"]["current"])
-    if tally["eddington"]:
-        score_eddington(s, g, t, x, y, z, flux, P, tally["score"]["eddington"])
-
-
-@njit
-def score_exit(P, x, mcdc):
-    tally = mcdc["tally"]
-    material = mcdc["materials"][P["material_ID"]]
-
-    s = P["sensitivity_ID"]
-    mu, azi = mesh_get_angular_index(P, tally["mesh"])
-    g, outside_energy = mesh_get_energy_index(P, tally["mesh"], mcdc)
-
-    # Outside grid?
-    if outside_energy:
-        return
+    # The tally index
+    idx = (
+        s * stride["sensitivity"]
+        + mu * stride["mu"]
+        + azi * stride["azi"]
+        + g * stride["g"]
+        + it * stride["t"]
+        + ix * stride["x"]
+        + iy * stride["y"]
+        + iz * stride["z"]
+    )
 
     # Score
-    flux = P["w"] / abs(P["ux"])
-    score_flux(s, g, 0, x, 0, 0, mu, azi, flux, tally["score"]["exit"])
-
-
-@njit
-def score_flux(s, g, t, x, y, z, mu, azi, flux, score):
-    score["bin"][s, g, t, x, y, z, mu, azi] += flux
-
-
-@njit
-def score_current(s, g, t, x, y, z, flux, P, score):
-    score["bin"][s, g, t, x, y, z, 0] += flux * P["ux"]
-    score["bin"][s, g, t, x, y, z, 1] += flux * P["uy"]
-    score["bin"][s, g, t, x, y, z, 2] += flux * P["uz"]
+    flux = distance * P["w"]
+    tally[TALLY_SCORE, idx] += flux
 
 
 @njit
-def score_eddington(s, g, t, x, y, z, flux, P, score):
-    ux = P["ux"]
-    uy = P["uy"]
-    uz = P["uz"]
-    score["bin"][s, g, t, x, y, z, 0] += flux * ux * ux
-    score["bin"][s, g, t, x, y, z, 1] += flux * ux * uy
-    score["bin"][s, g, t, x, y, z, 2] += flux * ux * uz
-    score["bin"][s, g, t, x, y, z, 3] += flux * uy * uy
-    score["bin"][s, g, t, x, y, z, 4] += flux * uy * uz
-    score["bin"][s, g, t, x, y, z, 5] += flux * uz * uz
+def tally_reduce(data, mcdc):
+    tally = data[TALLY]
 
-
-@njit
-def score_reduce_bin(score, mcdc):
     # Normalize
-    score["bin"][:] /= mcdc["setting"]["N_particle"]
+    N_particle = mcdc["setting"]["N_particle"]
+    tally[TALLY_SCORE][:] /= N_particle
 
     # MPI Reduce
-    buff = np.zeros_like(score["bin"])
+    buff = np.zeros_like(tally[TALLY_SCORE])
     with objmode():
-        MPI.COMM_WORLD.Reduce(np.array(score["bin"]), buff, MPI.SUM, 0)
-    score["bin"][:] = buff
+        MPI.COMM_WORLD.Reduce(tally[TALLY_SCORE], buff, MPI.SUM, 0)
+    tally[TALLY_SCORE][:] = buff
 
 
 @njit
-def score_closeout_history(score):
-    # Accumulate score and square of score into mean and sdev
-    score["mean"][:] += score["bin"]
-    score["sdev"][:] += np.square(score["bin"])
+def tally_accumulate(data, mcdc):
+    tally = data[TALLY]
+    N_bin = mcdc['tally']['N_bin']
 
-    # Reset bin
-    score["bin"].fill(0.0)
+    for i in range(N_bin):
+        # Accumulate score and square of score into sum and sum_sq
+        score = tally[TALLY_SCORE, i]
+        tally[TALLY_SUM, i] += score
+        tally[TALLY_SUM_SQ, i] += score * score
+
+        # Reset score bin
+        tally[TALLY_SCORE, i] = 0.0
 
 
 @njit
-def score_closeout(score, mcdc):
+def tally_closeout(data, mcdc):
+    tally = data[TALLY]
     N_history = mcdc["setting"]["N_particle"]
 
     if mcdc["setting"]["N_batch"] > 1:
@@ -1987,48 +1945,24 @@ def score_closeout(score, mcdc):
 
     else:
         # MPI Reduce
-        buff = np.zeros_like(score["mean"])
-        buff_sq = np.zeros_like(score["sdev"])
+        buff = np.zeros_like(tally[TALLY_SUM])
+        buff_sq = np.zeros_like(tally[TALLY_SUM_SQ])
         with objmode():
-            MPI.COMM_WORLD.Reduce(np.array(score["mean"]), buff, MPI.SUM, 0)
-            MPI.COMM_WORLD.Reduce(np.array(score["sdev"]), buff_sq, MPI.SUM, 0)
-        score["mean"][:] = buff
-        score["sdev"][:] = buff_sq
-
-    # Store results
-    score["mean"][:] = score["mean"] / N_history
-    score["sdev"][:] = np.sqrt(
-        (score["sdev"] / N_history - np.square(score["mean"])) / (N_history - 1)
+            MPI.COMM_WORLD.Reduce(tally[TALLY_SUM], buff, MPI.SUM, 0)
+            MPI.COMM_WORLD.Reduce(tally[TALLY_SUM_SQ], buff_sq, MPI.SUM, 0)
+        tally[TALLY_SUM] = buff
+        tally[TALLY_SUM_SQ] = buff_sq
+
+    # Calculate and store statistics
+    #   sum --> mean
+    #   sum_sq --> standard deviation
+    tally[TALLY_SUM] = tally[TALLY_SUM] / N_history
+    tally[TALLY_SUM_SQ] = np.sqrt(
+        (tally[TALLY_SUM_SQ] / N_history - np.square(tally[TALLY_SUM]))
+        / (N_history - 1)
     )
 
 
-@njit
-def tally_reduce_bin(mcdc):
-    tally = mcdc["tally"]
-
-    for name in literal_unroll(score_list):
-        if tally[name]:
-            score_reduce_bin(tally["score"][name], mcdc)
-
-
-@njit
-def tally_closeout_history(mcdc):
-    tally = mcdc["tally"]
-
-    for name in literal_unroll(score_list):
-        if tally[name]:
-            score_closeout_history(tally["score"][name])
-
-
-@njit
-def tally_closeout(mcdc):
-    tally = mcdc["tally"]
-
-    for name in literal_unroll(score_list):
-        if tally[name]:
-            score_closeout(tally["score"][name], mcdc)
-
-
 # =============================================================================
 # Eigenvalue tally operations
 # =============================================================================
@@ -2247,7 +2181,7 @@ def eigenvalue_tally_closeout(mcdc):
 
 
 @njit
-def move_to_event(P, mcdc):
+def move_to_event(P, data, mcdc):
     # =========================================================================
     # Get distances to events
     # =========================================================================
@@ -2327,8 +2261,8 @@ def move_to_event(P, mcdc):
             P["alive"] = False
 
     # Score tracklength tallies
-    if mcdc["tally"]["tracklength"] and mcdc["cycle_active"]:
-        score_tracklength(P, distance, mcdc)
+    if mcdc["cycle_active"]:
+        score_tracklength(P, distance, data, mcdc)
     if mcdc["setting"]["mode_eigenvalue"]:
         eigenvalue_tally(P, distance, mcdc)
 
@@ -2499,13 +2433,6 @@ def surface_crossing(P, mcdc):
     # Record old material for sensitivity quantification
     material_ID_old = P["material_ID"]
 
-    # Tally particle exit
-    if mcdc["tally"]["exit"] and not P["alive"]:
-        # Reflectance if P["surface_ID"] == 0, else transmittance
-        exit_idx = surface_exit_evaluate(P)
-        # Score on tally
-        score_exit(P, exit_idx, mcdc)
-
     # Check new cell?
     if P["alive"] and not surface["reflective"]:
         cell = mcdc["cells"][P["cell_ID"]]
@@ -4937,78 +4864,47 @@ def uq_reset(mcdc, seed):
 
 
 @njit
-def uq_tally_closeout_history(mcdc):
-    tally = mcdc["tally"]
+def uq_tally_closeout_history(data, mcdc):
+    tally = data[TALLY]
     uq_tally = mcdc["technique"]["uq_tally"]
 
-    for name in literal_unroll(score_list):
-        if uq_tally[name]:
-            uq_score_closeout_history(tally["score"][name], uq_tally["score"][name])
-
-
-@njit
-def uq_score_closeout_history(score, uq_score):
     # Assumes N_batch > 1
     # Accumulate square of history score, but continue to accumulate bin
-    history_bin = score["bin"] - uq_score["batch_bin"]
-    uq_score["batch_var"][:] += history_bin**2
-    uq_score["batch_bin"] = score["bin"]
+    history_bin = tally[TALLY_SCORE] - uq_tally["batch_bin"]
+    uq_tally["batch_var"][:] += history_bin**2
+    uq_tally["batch_bin"] = tally[TALLY_SCORE]
 
 
 @njit
 def uq_tally_closeout_batch(mcdc):
     uq_tally = mcdc["technique"]["uq_tally"]
 
-    for name in literal_unroll(score_list):
-        if uq_tally[name]:
-            # Reset bin
-            uq_tally["score"][name]["batch_bin"].fill(0.0)
-            uq_reduce_bin(uq_tally["score"][name])
-
+    # Reset bin
+    uq_tally["batch_bin"].fill(0.0)
 
-@njit
-def uq_reduce_bin(score):
     # MPI Reduce
-    buff = np.zeros_like(score["batch_var"])
+    buff = np.zeros_like(uq_tally["batch_var"])
     with objmode():
-        MPI.COMM_WORLD.Reduce(np.array(score["batch_var"]), buff, MPI.SUM, 0)
-    score["batch_var"][:] = buff
+        MPI.COMM_WORLD.Reduce(np.array(uq_tally["batch_var"]), buff, MPI.SUM, 0)
+    uq_tally["batch_var"][:] = buff
 
 
 @njit
-def uq_tally_closeout(mcdc):
-    tally = mcdc["tally"]
+def uq_tally_closeout(data, mcdc):
+    tally = data[TALLY]
     uq_tally = mcdc["technique"]["uq_tally"]
-
-    for name in literal_unroll(score_list):
-        # Uq_tally implies tally, but tally does not imply uq_tally
-        if uq_tally[name]:
-            uq_score_closeout(name, mcdc)
-        elif tally[name]:
-            score_closeout(tally["score"][name], mcdc)
-
-
-@njit
-def uq_score_closeout(name, mcdc):
-    score = mcdc["tally"]["score"][name]
-    uq_score = mcdc["technique"]["uq_tally"]["score"][name]
-
     N_history = mcdc["setting"]["N_particle"]
 
-    # At this point, score["sdev"] is still just the sum of the squared mean from every batch
-    uq_score["batch_var"] = (uq_score["batch_var"] / N_history - score["sdev"]) / (
-        N_history - 1
-    )
+    uq_tally["batch_var"] = (
+        uq_tally["batch_var"] / N_history - tally[TALLY_SUM_SQ]
+    ) / (N_history - 1)
 
     # If we're here, N_batch > 1
     N_history = mcdc["setting"]["N_batch"]
 
     # Store results
-    score["mean"][:] = score["mean"] / N_history
-    uq_score["batch_var"] /= N_history
-    uq_score["batch_bin"] = (score["sdev"] - N_history * np.square(score["mean"])) / (
+    mean = tally[TALLY_SUM] / N_history
+    uq_tally["batch_var"] /= N_history
+    uq_tally["batch_bin"] = (tally[TALLY_SUM_SQ] - N_history * np.square(mean)) / (
         N_history - 1
     )
-    score["sdev"][:] = np.sqrt(
-        (score["sdev"] / N_history - np.square(score["mean"])) / (N_history - 1)
-    )
diff --git a/mcdc/loop.py b/mcdc/loop.py
index e550a38..02d3638 100644
--- a/mcdc/loop.py
+++ b/mcdc/loop.py
@@ -30,7 +30,7 @@ from mcdc.print_ import (
 
 
 @njit(cache=True)
-def loop_fixed_source(mcdc):
+def loop_fixed_source(data, mcdc):
     # Loop over batches
     for idx_batch in range(mcdc["setting"]["N_batch"]):
         mcdc["idx_batch"] = idx_batch
@@ -51,14 +51,14 @@ def loop_fixed_source(mcdc):
 
             # Loop over source particles
             seed_source = kernel.split_seed(seed_census, SEED_SPLIT_SOURCE)
-            loop_source(seed_source, mcdc)
+            loop_source(seed_source, data, mcdc)
 
             # Loop over source precursors
             if mcdc["bank_precursor"]["size"] > 0:
                 seed_source_precursor = kernel.split_seed(
                     seed_census, SEED_SPLIT_SOURCE_PRECURSOR
                 )
-                loop_source_precursor(seed_source_precursor, mcdc)
+                loop_source_precursor(seed_source_precursor, data, mcdc)
 
             # Time census closeout
             if idx_census < mcdc["setting"]["N_census"] - 1:
@@ -76,17 +76,16 @@ def loop_fixed_source(mcdc):
             mcdc["bank_active"]["size"] = 0
 
             # Tally history closeout
-            kernel.tally_reduce_bin(mcdc)
-            kernel.tally_closeout_history(mcdc)
+            kernel.tally_reduce(data, mcdc)
+            kernel.tally_accumulate(data, mcdc)
             # Uq closeout
             if mcdc["technique"]["uq"]:
                 kernel.uq_tally_closeout_batch(mcdc)
 
     # Tally closeout
     if mcdc["technique"]["uq"]:
-        kernel.uq_tally_closeout(mcdc)
-    else:
-        kernel.tally_closeout(mcdc)
+        kernel.uq_tally_closeout(data, mcdc)
+    kernel.tally_closeout(data, mcdc)
 
 
 # =========================================================================
@@ -107,8 +106,8 @@ def loop_eigenvalue(mcdc):
         # Tally "history" closeout
         kernel.eigenvalue_tally_closeout_history(mcdc)
         if mcdc["cycle_active"]:
-            kernel.tally_reduce_bin(mcdc)
-            kernel.tally_closeout_history(mcdc)
+            kernel.tally_reduce(mcdc)
+            kernel.tally_accumulate(mcdc)
 
         # Print progress
         with objmode():
@@ -134,7 +133,7 @@ def loop_eigenvalue(mcdc):
 
 
 @njit(cache=True)
-def loop_source(seed, mcdc):
+def loop_source(seed, data, mcdc):
     # Progress bar indicator
     N_prog = 0
 
@@ -200,7 +199,7 @@ def loop_source(seed, mcdc):
                 mcdc["particle_track_particle_ID"] += 1
 
             # Particle loop
-            loop_particle(P, mcdc)
+            loop_particle(P, data, mcdc)
 
         # =====================================================================
         # Closeout
@@ -208,11 +207,11 @@ def loop_source(seed, mcdc):
 
         # Tally history closeout for one-batch fixed-source simulation
         if not mcdc["setting"]["mode_eigenvalue"] and mcdc["setting"]["N_batch"] == 1:
-            kernel.tally_closeout_history(mcdc)
+            kernel.tally_accumulate(data, mcdc)
 
         # Tally history closeout for multi-batch uq simulation
         if mcdc["technique"]["uq"]:
-            kernel.uq_tally_closeout_history(mcdc)
+            kernel.uq_tally_closeout_history(data, mcdc)
 
         # Progress printout
         percent = (idx_work + 1.0) / mcdc["mpi_work_size"]
@@ -244,14 +243,14 @@ def loop_source(seed, mcdc):
                         mcdc["particle_track_particle_ID"] += 1
 
                     # Particle loop
-                    loop_particle(P, mcdc)
+                    loop_particle(P, data, mcdc)
 
                     # Tally history closeout for one-batch fixed-source simulation
                     if (
                         not mcdc["setting"]["mode_eigenvalue"]
                         and mcdc["setting"]["N_batch"] == 1
                     ):
-                        kernel.tally_closeout_history(mcdc)
+                        kernel.tally_accumulate(data, mcdc)
 
                 # Send all domain particle banks
                 kernel.dd_particle_send(mcdc)
@@ -281,7 +280,7 @@ def loop_source(seed, mcdc):
 
 
 @njit(cache=True)
-def loop_particle(P, mcdc):
+def loop_particle(P, data, mcdc):
     # Particle tracker
     if mcdc["setting"]["track_particle"]:
         kernel.track_particle(P, mcdc)
@@ -293,7 +292,7 @@ def loop_particle(P, mcdc):
             P["cell_ID"] = kernel.get_particle_cell(P, 0, trans, mcdc)
 
         # Determine and move to event
-        kernel.move_to_event(P, mcdc)
+        kernel.move_to_event(P, data, mcdc)
         event = P["event"]
 
         # The & operator here is a bitwise and.
@@ -748,7 +747,7 @@ def davidson(mcdc):
 
 
 @njit(cache=True)
-def loop_source_precursor(seed, mcdc):
+def loop_source_precursor(seed, data, mcdc):
     # TODO: censussed neutrons seeding is still not reproducible
 
     # Progress bar indicator
@@ -878,7 +877,7 @@ def loop_source_precursor(seed, mcdc):
                         mcdc["particle_track_particle_ID"] += 1
 
                     # Particle loop
-                    loop_particle(P, mcdc)
+                    loop_particle(P, data, mcdc)
 
         # =====================================================================
         # Closeout
@@ -886,7 +885,7 @@ def loop_source_precursor(seed, mcdc):
 
         # Tally history closeout for fixed-source simulation
         if not mcdc["setting"]["mode_eigenvalue"]:
-            kernel.tally_closeout_history(mcdc)
+            kernel.tally_accumulate(data, mcdc)
 
         # Progress printout
         percent = (idx_work + 1.0) / mcdc["mpi_work_size_precursor"]
diff --git a/mcdc/main.py b/mcdc/main.py
index 1533efc..82815af 100644
--- a/mcdc/main.py
+++ b/mcdc/main.py
@@ -105,7 +105,7 @@ def run():
     #   Set up and get the global variable container `mcdc` based on
     #   input deck
     preparation_start = MPI.Wtime()
-    mcdc = prepare()
+    data, mcdc = prepare()
     mcdc["runtime_preparation"] = MPI.Wtime() - preparation_start
 
     # Print banner, hardware configuration, and header
@@ -121,12 +121,12 @@ def run():
     elif mcdc["setting"]["mode_eigenvalue"]:
         loop_eigenvalue(mcdc)
     else:
-        loop_fixed_source(mcdc)
+        loop_fixed_source(data, mcdc)
     mcdc["runtime_simulation"] = MPI.Wtime() - simulation_start
 
     # Output: generate hdf5 output files
     output_start = MPI.Wtime()
-    generate_hdf5(mcdc)
+    generate_hdf5(data, mcdc)
     mcdc["runtime_output"] = MPI.Wtime() - output_start
 
     # Stop timer
@@ -188,7 +188,6 @@ def dd_prepare():
     d_Ny = input_deck.technique["dd_mesh"]["y"].size - 1
     d_Nz = input_deck.technique["dd_mesh"]["z"].size - 1
 
-    input_deck.setting["bank_active_buff"] = 1000
     if input_deck.technique["dd_exchange_rate"] == None:
         input_deck.technique["dd_exchange_rate"] = 100
 
@@ -482,13 +481,53 @@ def prepare():
     # Tally
     # =========================================================================
 
-    for name in type_.tally.names:
-        if name not in ["score", "mesh"]:
-            mcdc["tally"][name] = input_deck.tally[name]
     # Set mesh
     for name in type_.mesh_names:
         mcdc["tally"]["mesh"][name] = input_deck.tally["mesh"][name]
 
+    # Tally strides
+    N_sensitivity = input_deck.setting["N_sensitivity"]
+    Ns = 1 + N_sensitivity
+    if input_deck.technique["dsm_order"] == 2:
+        Ns = 1 + 2 * N_sensitivity + int(0.5 * N_sensitivity * (N_sensitivity - 1))
+    card = input_deck.tally["mesh"]
+    Nmu = len(card["mu"]) - 1
+    N_azi = len(card["azi"]) - 1
+    Ng = len(card["g"]) - 1
+    Nx = len(card["x"]) - 1
+    Ny = len(card["y"]) - 1
+    Nz = len(card["z"]) - 1
+    Nt = len(card["t"]) - 1
+    stride = 1
+    if Nz > 1:
+        mcdc["tally"]["stride"]["z"] = stride
+        stride *= Nz
+    if Ny > 1:
+        mcdc["tally"]["stride"]["y"] = stride
+        stride *= Ny
+    if Nx > 1:
+        mcdc["tally"]["stride"]["x"] = stride
+        stride *= Nx
+    if Nt > 1:
+        mcdc["tally"]["stride"]["t"] = stride
+        stride *= Nt
+    if Ng > 1:
+        mcdc["tally"]["stride"]["g"] = stride
+        stride *= Ng
+    if N_azi > 1:
+        mcdc["tally"]["stride"]["azi"] = stride
+        stride *= N_azi
+    if Nmu > 1:
+        mcdc["tally"]["stride"]["mu"] = stride
+        stride *= Nmu
+    if Ns > 1:
+        mcdc["tally"]["stride"]["sensitivity"] = stride
+    N_bin = Ns * Nmu * N_azi * Ng * Nt * Nx * Ny * Nz
+    mcdc['tally']['N_bin'] = N_bin
+
+    # Set tally data
+    tally = np.zeros((3, N_bin), dtype=type_.float64)
+
     # =========================================================================
     # Setting
     # =========================================================================
@@ -675,11 +714,6 @@ def prepare():
     # Variance Deconvolution - UQ
     # =========================================================================
     if mcdc["technique"]["uq"]:
-        # Assumes that all tallies will also be uq tallies
-        for name in type_.uq_tally.names:
-            if name != "score":
-                mcdc["technique"]["uq_tally"][name] = input_deck.tally[name]
-
         M = len(input_deck.uq_deltas["materials"])
         for i in range(M):
             idm = input_deck.uq_deltas["materials"][i]["ID"]
@@ -839,7 +873,13 @@ def prepare():
                     "w"
                 ]
 
-    return mcdc
+    # =========================================================================
+    # Finalize data: wrapping into a tuple
+    # =========================================================================
+
+    data = (tally,)
+
+    return data, mcdc
 
 
 def dictlist_to_h5group(dictlist, input_group, name):
@@ -859,7 +899,7 @@ def dict_to_h5group(dict_, group):
             group[k] = v
 
 
-def generate_hdf5(mcdc):
+def generate_hdf5(data, mcdc):
     if mcdc["mpi_master"]:
         if mcdc["setting"]["progress_bar"]:
             print_msg("")
@@ -883,38 +923,48 @@ def generate_hdf5(mcdc):
                 )
 
             # Tally
-            T = mcdc["tally"]
-            f.create_dataset("tally/grid/t", data=T["mesh"]["t"])
-            f.create_dataset("tally/grid/x", data=T["mesh"]["x"])
-            f.create_dataset("tally/grid/y", data=T["mesh"]["y"])
-            f.create_dataset("tally/grid/z", data=T["mesh"]["z"])
-            f.create_dataset("tally/grid/mu", data=T["mesh"]["mu"])
-            f.create_dataset("tally/grid/azi", data=T["mesh"]["azi"])
-            f.create_dataset("tally/grid/g", data=T["mesh"]["g"])
+            mesh = mcdc["tally"]["mesh"]
+            tally = data[TALLY]
+            f.create_dataset("tally/grid/t", data=mesh["t"])
+            f.create_dataset("tally/grid/x", data=mesh["x"])
+            f.create_dataset("tally/grid/y", data=mesh["y"])
+            f.create_dataset("tally/grid/z", data=mesh["z"])
+            f.create_dataset("tally/grid/mu", data=mesh["mu"])
+            f.create_dataset("tally/grid/azi", data=mesh["azi"])
+            f.create_dataset("tally/grid/g", data=mesh["g"])
+
+            # Shape
+            N_sensitivity = input_deck.setting["N_sensitivity"]
+            Ns = 1 + N_sensitivity
+            if input_deck.technique["dsm_order"] == 2:
+                Ns = 1 + 2 * N_sensitivity + int(0.5 * N_sensitivity * (N_sensitivity - 1))
+            card = input_deck.tally['mesh']
+            Nmu = len(card["mu"]) - 1
+            N_azi = len(card["azi"]) - 1
+            Ng = len(card["g"]) - 1
+            Nx = len(card["x"]) - 1
+            Ny = len(card["y"]) - 1
+            Nz = len(card["z"]) - 1
+            Nt = len(card["t"]) - 1
+            shape = (3, Ns, Nmu, N_azi, Ng, Nt, Nx, Ny, Nz)
+
+            # Reshape tally
+            tally = data[TALLY]
+            tally = tally.reshape(shape)
+
+            mean = np.squeeze(tally[TALLY_SUM])
+            sdev = np.squeeze(tally[TALLY_SUM_SQ])
 
             # Scores
-            for name in T["score"].dtype.names:
-                if mcdc["tally"][name]:
-                    name_h5 = name.replace("_", "-")
-                    f.create_dataset(
-                        "tally/" + name_h5 + "/mean",
-                        data=np.squeeze(T["score"][name]["mean"]),
-                    )
-                    f.create_dataset(
-                        "tally/" + name_h5 + "/sdev",
-                        data=np.squeeze(T["score"][name]["sdev"]),
-                    )
-                    if mcdc["technique"]["uq_tally"][name]:
-                        mc_var = mcdc["technique"]["uq_tally"]["score"][name][
-                            "batch_var"
-                        ]
-                        tot_var = mcdc["technique"]["uq_tally"]["score"][name][
-                            "batch_bin"
-                        ]
-                        f.create_dataset(
-                            "tally/" + name_h5 + "/uq_var",
-                            data=np.squeeze(tot_var - mc_var),
-                        )
+            f.create_dataset("tally/flux/mean", data=mean)
+            f.create_dataset("tally/flux/sdev", data=sdev)
+            if mcdc["technique"]["uq_tally"]:
+                mc_var = mcdc["technique"]["uq_tally"]["batch_var"]
+                tot_var = mcdc["technique"]["uq_tally"]["batch_bin"]
+                f.create_dataset(
+                    "tally/flux/uq_var",
+                    data=np.squeeze((tot_var - mc_var).reshape(shape)),
+                )
 
             # Eigenvalues
             if mcdc["setting"]["mode_eigenvalue"]:
diff --git a/mcdc/type_.py b/mcdc/type_.py
index 7aa92bc..c5257bc 100644
--- a/mcdc/type_.py
+++ b/mcdc/type_.py
@@ -524,76 +524,30 @@ def make_type_source(input_deck):
 # ==============================================================================
 
 
-# Score lists
-score_list = (
-    "flux",
-    "density",
-    "fission",
-    "total",
-    "current",
-    "eddington",
-    "exit",
-)
-
-
 def make_type_tally(input_deck):
     global tally
 
-    # Number of sensitivitys parameters
-    N_sensitivity = input_deck.setting["N_sensitivity"]
-
-    # Number of tally scores
-    Ns = 1 + N_sensitivity
-    if input_deck.technique["dsm_order"] == 2:
-        Ns = 1 + 2 * N_sensitivity + int(0.5 * N_sensitivity * (N_sensitivity - 1))
-
-    # Get card
-    card = input_deck.tally
-
-    # Tally estimator flags
-    struct = [("tracklength", bool_)]
-
-    def make_type_score(shape):
-        return np.dtype(
-            [
-                ("bin", float64, shape),
-                ("mean", float64, shape),
-                ("sdev", float64, shape),
-            ]
-        )
-
     # Mesh
-    mesh, Nx, Ny, Nz, Nt, Nmu, N_azi, Ng = make_type_mesh(card["mesh"])
-    struct += [("mesh", mesh)]
+    mesh, Nx, Ny, Nz, Nt, Nmu, N_azi, Ng = make_type_mesh(input_deck.tally["mesh"])
+    struct = [("mesh", mesh)]
 
-    # Scores and shapes
-    scores_shapes = [
-        ["flux", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["density", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["fission", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["total", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["current", (Ns, Ng, Nt, Nx, Ny, Nz, 3)],
-        ["eddington", (Ns, Ng, Nt, Nx, Ny, Nz, 6)],
-        ["exit", (Ns, Ng, Nt, 2, Ny, Nz, Nmu, N_azi)],
+    # Make tally structure
+    # Tally strides
+    stride = [
+        ("sensitivity", int64),
+        ("mu", int64),
+        ("azi", int64),
+        ("g", int64),
+        ("t", int64),
+        ("x", int64),
+        ("y", int64),
+        ("z", int64),
     ]
+    struct += [("stride", stride)]
 
-    # Add score flags to structure
-    for i in range(len(scores_shapes)):
-        name = scores_shapes[i][0]
-        struct += [(name, bool_)]
-
-    # Add scores to structure
-    scores_struct = []
-    for i in range(len(scores_shapes)):
-        name = scores_shapes[i][0]
-        shape = scores_shapes[i][1]
-        if not card[name]:
-            shape = (0,) * len(shape)
-        scores_struct += [(name, make_type_score(shape))]
-    scores = np.dtype(scores_struct)
-    struct += [("score", scores)]
+    # Total number of bins
+    struct += [("N_bin", int64)]
 
-    # Make tally structure
     tally = np.dtype(struct)
 
 
@@ -900,14 +854,6 @@ def make_type_technique(input_deck):
 def make_type_uq_tally(input_deck):
     global uq_tally
 
-    def make_type_uq_score(shape):
-        return np.dtype(
-            [
-                ("batch_bin", float64, shape),
-                ("batch_var", float64, shape),
-            ]
-        )
-
     # Tally estimator flags
     struct = []
 
@@ -920,32 +866,14 @@ def make_type_uq_tally(input_deck):
     # Mesh, but doesn't need to be added
     mesh, Nx, Ny, Nz, Nt, Nmu, N_azi, Ng = make_type_mesh(tally_card["mesh"])
 
-    # Scores and shapes
-    scores_shapes = [
-        ["flux", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["density", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["fission", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["total", (Ns, Ng, Nt, Nx, Ny, Nz, Nmu, N_azi)],
-        ["current", (Ns, Ng, Nt, Nx, Ny, Nz, 3)],
-        ["eddington", (Ns, Ng, Nt, Nx, Ny, Nz, 6)],
-        ["exit", (Ns, Ng, Nt, 2, Ny, Nz, Nmu, N_azi)],
-    ]
-
-    # Add score flags to structure
-    for i in range(len(scores_shapes)):
-        name = scores_shapes[i][0]
-        struct += [(name, bool_)]
-
-    # Add scores to structure
-    scores_struct = []
-    for i in range(len(scores_shapes)):
-        name = scores_shapes[i][0]
-        shape = scores_shapes[i][1]
-        if not tally_card[name]:
-            shape = (0,) * len(shape)
-        scores_struct += [(name, make_type_uq_score(shape))]
-    scores = np.dtype(scores_struct)
-    struct += [("score", scores)]
+    # Tally shape and bins
+    if input_deck.technique['uq']:
+        N_bin = Ns * Nmu * N_azi * Ng * Nt * Nx * Ny * Nz
+    else:
+        N_bin = 0
+    shape = (N_bin,)
+    struct += [("batch_bin", float64, shape)]
+    struct += [("batch_var", float64, shape)]
 
     # Make tally structure
     uq_tally = np.dtype(struct)
diff --git a/test/regression/azurv1/answer.h5 b/test/regression/azurv1/answer.h5
index 3f35429..f043a5d 100644
Binary files a/test/regression/azurv1/answer.h5 and b/test/regression/azurv1/answer.h5 differ
diff --git a/test/regression/c5g7_2d_k_eigenvalue/answer.h5 b/test/regression/c5g7_2d_k_eigenvalue/answer.h5
index 40690e8..75233c9 100644
Binary files a/test/regression/c5g7_2d_k_eigenvalue/answer.h5 and b/test/regression/c5g7_2d_k_eigenvalue/answer.h5 differ
diff --git a/test/regression/cooper2/answer.h5 b/test/regression/cooper2/answer.h5
index 9546cc1..7c8d0d3 100644
Binary files a/test/regression/cooper2/answer.h5 and b/test/regression/cooper2/answer.h5 differ
diff --git a/test/regression/dsm_azurv1/answer.h5 b/test/regression/dsm_azurv1/answer.h5
index 0c1afb2..32be7ea 100644
Binary files a/test/regression/dsm_azurv1/answer.h5 and b/test/regression/dsm_azurv1/answer.h5 differ
diff --git a/test/regression/dsm_lattice/answer.h5 b/test/regression/dsm_lattice/answer.h5
index ea8ee26..3069156 100644
Binary files a/test/regression/dsm_lattice/answer.h5 and b/test/regression/dsm_lattice/answer.h5 differ
diff --git a/test/regression/inf_shem361/answer.h5 b/test/regression/inf_shem361/answer.h5
index abe8ddd..827ea09 100644
Binary files a/test/regression/inf_shem361/answer.h5 and b/test/regression/inf_shem361/answer.h5 differ
diff --git a/test/regression/inf_shem361_k_eigenvalue/answer.h5 b/test/regression/inf_shem361_k_eigenvalue/answer.h5
index 9e634c8..7a0ac08 100644
Binary files a/test/regression/inf_shem361_k_eigenvalue/answer.h5 and b/test/regression/inf_shem361_k_eigenvalue/answer.h5 differ
diff --git a/test/regression/inf_shem361_td/answer.h5 b/test/regression/inf_shem361_td/answer.h5
index e4d2d3d..d1a03bf 100644
Binary files a/test/regression/inf_shem361_td/answer.h5 and b/test/regression/inf_shem361_td/answer.h5 differ
diff --git a/test/regression/iqmc_cooper2/answer.h5 b/test/regression/iqmc_cooper2/answer.h5
index f9a7953..62ed87f 100644
Binary files a/test/regression/iqmc_cooper2/answer.h5 and b/test/regression/iqmc_cooper2/answer.h5 differ
diff --git a/test/regression/iqmc_kornreich_davidson/answer.h5 b/test/regression/iqmc_kornreich_davidson/answer.h5
index 92a74a5..4eaa8b4 100644
Binary files a/test/regression/iqmc_kornreich_davidson/answer.h5 and b/test/regression/iqmc_kornreich_davidson/answer.h5 differ
diff --git a/test/regression/iqmc_kornreich_pi/answer.h5 b/test/regression/iqmc_kornreich_pi/answer.h5
index c833570..e8d37e1 100644
Binary files a/test/regression/iqmc_kornreich_pi/answer.h5 and b/test/regression/iqmc_kornreich_pi/answer.h5 differ
diff --git a/test/regression/iqmc_reed/answer.h5 b/test/regression/iqmc_reed/answer.h5
index a1b284b..0fd6ea5 100644
Binary files a/test/regression/iqmc_reed/answer.h5 and b/test/regression/iqmc_reed/answer.h5 differ
diff --git a/test/regression/iqmc_sood_davidson/answer.h5 b/test/regression/iqmc_sood_davidson/answer.h5
index 71ab009..3d79402 100644
Binary files a/test/regression/iqmc_sood_davidson/answer.h5 and b/test/regression/iqmc_sood_davidson/answer.h5 differ
diff --git a/test/regression/iqmc_sood_pi/answer.h5 b/test/regression/iqmc_sood_pi/answer.h5
index 9182dbf..f39e1e6 100644
Binary files a/test/regression/iqmc_sood_pi/answer.h5 and b/test/regression/iqmc_sood_pi/answer.h5 differ
diff --git a/test/regression/kobayashi3-TD/answer.h5 b/test/regression/kobayashi3-TD/answer.h5
index 7d40959..a5b463d 100644
Binary files a/test/regression/kobayashi3-TD/answer.h5 and b/test/regression/kobayashi3-TD/answer.h5 differ
diff --git a/test/regression/kornreich/answer.h5 b/test/regression/kornreich/answer.h5
index d704602..5d1ec32 100644
Binary files a/test/regression/kornreich/answer.h5 and b/test/regression/kornreich/answer.h5 differ
diff --git a/test/regression/run.py b/test/regression/run.py
index 9ca9e6f..3eeb958 100644
--- a/test/regression/run.py
+++ b/test/regression/run.py
@@ -113,32 +113,26 @@ for i, name in enumerate(names):
     runtimes[-1] = output["runtime/total"][()]
     print("  (%.2f seconds)" % runtimes[-1])
 
-    # Compare all scores
-    for score in [key for key in output["tally"].keys() if key != "grid"]:
-        # Compare mean, sdev, and uq_var (if available)
-        for result in [key for key in output["tally/" + score].keys()]:
-            result_name = "tally/" + score + "/" + result
-            a = output[result_name][:]
-            b = answer[result_name][:]
+    # Compare mean, sdev, and uq_var (if available)
+    for result in [key for key in output["tally/flux"].keys()]:
+        if "iqmc" in output.keys():
+            break
+        if result in ["grid"]:
+            continue
 
-            # Passed?
-            if np.isclose(a, b).all():
-                print(
-                    Fore.GREEN
-                    + "  {}: Passed".format(score + "/" + result)
-                    + Style.RESET_ALL
-                )
-            else:
-                all_pass = False
-                error_msgs[-1].append(
-                    "Differences in %s"
-                    % (name + "/" + score + "/" + result + "\n" + "{}".format(a - b))
-                )
-                print(
-                    Fore.RED
-                    + "  {}: Failed".format(score + "/" + result)
-                    + Style.RESET_ALL
-                )
+        result_name = "tally/flux/" + result
+        a = output[result_name][:]
+        b = answer[result_name][:]
+
+        # Passed?
+        if np.isclose(a, b).all():
+            print(Fore.GREEN + "  {}: Passed".format(result) + Style.RESET_ALL)
+        else:
+            all_pass = False
+            error_msgs[-1].append(
+                "Differences in %s" % (name + "/" + result + "\n" + "{}".format(a - b))
+            )
+            print(Fore.RED + "  {}: Failed".format(result) + Style.RESET_ALL)
 
     # Other quantities
     for result_name in ["k_mean", "k_sdev", "k_cycle", "k_eff"]:
diff --git a/test/regression/slab_absorbium/answer.h5 b/test/regression/slab_absorbium/answer.h5
index 835c8b0..b7d06ad 100644
Binary files a/test/regression/slab_absorbium/answer.h5 and b/test/regression/slab_absorbium/answer.h5 differ
diff --git a/test/regression/slab_absorbium/input.py b/test/regression/slab_absorbium/input.py
index 379a1b6..ff04b6c 100644
--- a/test/regression/slab_absorbium/input.py
+++ b/test/regression/slab_absorbium/input.py
@@ -38,7 +38,7 @@ mcdc.source(z=[0.0, 6.0], isotropic=True)
 
 # Tally: cell-average and cell-edge angular fluxes and currents
 mcdc.tally(
-    scores=["flux", "current"],
+    scores=["flux"],
     z=np.linspace(0.0, 6.0, 61),
     mu=np.linspace(-1.0, 1.0, 32 + 1),
 )
diff --git a/test/regression/slab_isobeam_td/answer.h5 b/test/regression/slab_isobeam_td/answer.h5
index 910dbce..fedcfe1 100644
Binary files a/test/regression/slab_isobeam_td/answer.h5 and b/test/regression/slab_isobeam_td/answer.h5 differ
diff --git a/test/regression/slab_moving/answer.h5 b/test/regression/slab_moving/answer.h5
index 41eb194..b258264 100644
Binary files a/test/regression/slab_moving/answer.h5 and b/test/regression/slab_moving/answer.h5 differ
diff --git a/test/regression/smrg7/answer.h5 b/test/regression/smrg7/answer.h5
index b47cb42..0441f17 100644
Binary files a/test/regression/smrg7/answer.h5 and b/test/regression/smrg7/answer.h5 differ
diff --git a/test/regression/smrg7/input.py b/test/regression/smrg7/input.py
index 1eadff8..9b1f790 100644
--- a/test/regression/smrg7/input.py
+++ b/test/regression/smrg7/input.py
@@ -379,7 +379,7 @@ source = mcdc.source(
 x_grid = np.linspace(-pitch * 17 * 9 / 2, pitch * 17 * 9 / 2, 9 + 1)
 y_grid = np.linspace(-pitch * 17 * 9 / 2, pitch * 17 * 9 / 2, 9 + 1)
 z_grid = np.linspace(-130, 130, 14)
-mcdc.tally(scores=["flux", "fission"], x=x_grid, y=y_grid, z=z_grid, g="all")
+mcdc.tally(scores=["flux"], x=x_grid, y=y_grid, z=z_grid, g="all")
 
 # Setting
 mcdc.setting(N_particle=30, census_bank_buff=2)
diff --git a/test/regression/variance_deconv/answer.h5 b/test/regression/variance_deconv/answer.h5
index 8411b96..c4b66a0 100644
Binary files a/test/regression/variance_deconv/answer.h5 and b/test/regression/variance_deconv/answer.h5 differ
diff --git a/test/regression/variance_deconv/input.py b/test/regression/variance_deconv/input.py
index fa3aedc..0cafe8e 100644
--- a/test/regression/variance_deconv/input.py
+++ b/test/regression/variance_deconv/input.py
@@ -23,8 +23,7 @@ mcdc.cell([+s3, -s4], m3)
 
 mcdc.source(point=[0.0, 0.0, 0.0], direction=[1.0, 0.0, 0.0])
 
-scores = ["exit"]
-mcdc.tally(scores=scores, x=np.linspace(0.0, 6.0, 2))
+mcdc.tally(scores=["flux"], x=np.linspace(0.0, 6.0, 7))
 
 mcdc.setting(N_particle=1e1, N_batch=1e1, progress_bar=False)
 
@@ -33,28 +32,3 @@ mcdc.uq(material=m2, distribution="uniform", capture=np.array([0.12]))
 mcdc.uq(material=m3, distribution="uniform", capture=np.array([0.5]))
 
 mcdc.run()
-
-# =========================================================================
-# Check output
-# =========================================================================
-
-output = h5py.File("output.h5", "r")
-answer = h5py.File("answer.h5", "r")
-for score in scores:
-    name = "tally/" + score + "/mean"
-    a = output[name][:]
-    b = answer[name][:]
-    assert np.isclose(a, b).all()
-
-    name = "tally/" + score + "/sdev"
-    a = output[name][:]
-    b = answer[name][:]
-    assert np.isclose(a, b).all()
-
-    name = "tally/" + score + "/uq_var"
-    a = output[name][:]
-    b = answer[name][:]
-    assert np.isclose(a, b).all()
-
-output.close()
-answer.close()
