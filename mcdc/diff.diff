diff --git a/mcdc/kernel.py b/mcdc/kernel.py
index 12bd27c..80564cb 100644
--- a/mcdc/kernel.py
+++ b/mcdc/kernel.py
@@ -1,8 +1,7 @@
 import math
 
 from mpi4py import MPI
-from numba import njit, objmode, literal_unroll
-import numba
+from numba import njit, objmode, literal_unroll, cuda
 
 import mcdc.type_ as type_
 
@@ -11,17 +10,18 @@ from mcdc.print_ import print_error
 from mcdc.type_ import score_list
 from mcdc.loop import loop_source
 
+import mcdc.adapt as adapt
 
 # =============================================================================
 # Random sampling
 # =============================================================================
 
-
+# Needs refactor for per-particle rng
 @njit
 def sample_isotropic_direction(P,mcdc):
     # Sample polar cosine and azimuthal angle uniformly
-    mu = 2.0 * stateful_rng(P,mcdc) - 1.0
-    azi = 2.0 * PI * stateful_rng(P,mcdc)
+    mu = 2.0 * local_rng(P,mcdc) - 1.0
+    azi = 2.0 * PI * local_rng(P,mcdc)
 
     # Convert to Cartesian coordinates
     c = (1.0 - mu**2) ** 0.5
@@ -34,10 +34,10 @@ def sample_isotropic_direction(P,mcdc):
 @njit
 def sample_white_direction(nx, ny, nz, P, mcdc):
     # Sample polar cosine
-    mu = math.sqrt(stateful_rng(P,mcdc))
+    mu = math.sqrt(local_rng(P,mcdc))
 
     # Sample azimuthal direction
-    azi = 2.0 * PI * stateful_rng(P,mcdc)
+    azi = 2.0 * PI * local_rng(P,mcdc)
     cos_azi = math.cos(azi)
     sin_azi = math.sin(azi)
     Ac = (1.0 - mu**2) ** 0.5
@@ -63,14 +63,14 @@ def sample_white_direction(nx, ny, nz, P, mcdc):
 
 @njit
 def sample_uniform(a, b, P, mcdc):
-    return a + stateful_rng(P, mcdc) * (b - a)
+    return a + local_rng(P, mcdc) * (b - a)
 
 
 # TODO: use cummulative density function and binary search
 @njit
 def sample_discrete(group, P, mcdc):
     tot = 0.0
-    xi = stateful_rng(P,mcdc)
+    xi = local_rng(P,mcdc)
     for i in range(group.shape[0]):
         tot += group[i]
         if tot > xi:
@@ -83,103 +83,25 @@ def sample_discrete(group, P, mcdc):
 # TODO: make g, c, and mod constants
 
 
+#! Revise - make rng state per-particle
 @njit
 def rng_rebase(mcdc):
     mcdc["rng_seed_base"] = mcdc["rng_seed"]
 
 
+#! Revise - make rng state per-particle
 @njit
 def rng_skip_ahead_strides(n, mcdc):
     rng_skip_ahead_(int(n * mcdc["rng_stride"]), mcdc)
 
 
+#! Revise - make rng state per-particle
 @njit
 def rng_skip_ahead(n, mcdc):
     rng_skip_ahead_(int(n), mcdc)
 
 
-
-
-@njit(numba.uint64(numba.uint64))
-def bot_64(a):
-    half_mask = 0xFFFFFFFF
-    return a & half_mask
-
-@njit(numba.uint64(numba.uint64))
-def top_64(a):
-    half_mask = 0xFFFFFFFF
-    return ( a >> 32 ) & half_mask
-    
-
-@njit(numba.uint64(numba.uint64,numba.uint64))
-def wrapping_mul_(a,b):
-    a_lo = bot_64(a)
-    a_hi = top_64(a)
-    b_lo = bot_64(b)
-    b_hi = top_64(b)
-    x = a_lo * b_lo
-    x_lo = bot_64(x)
-    x_hi = top_64(x)
-    y = bot_64(a_lo * b_hi)
-    z = bot_64(a_hi * b_lo)
-    top = bot_64(x_hi+y+z)
-    bot = x_lo
-    result = (top << 32) | bot
-    return result
-
-@njit(numba.uint64(numba.uint64,numba.uint64))
-def wrapping_mul(a,b):
-    mask = numba.uint64(0xFFFFFFFFFFFFFFFF)
-    return (a * b) & mask
-
-    
-@njit(numba.uint64(numba.uint64,numba.uint64))
-def wrapping_add(a,b):
-    a_lo = bot_64(a)
-    a_hi = top_64(a)
-    b_lo = bot_64(b)
-    b_hi = top_64(b)
-    x = a_lo + b_lo
-    x_lo = bot_64(x)
-    x_hi = top_64(x)
-    y = bot_64(a_hi + b_hi)
-    top = bot_64(x_hi+y)
-    bot = x_lo
-    result = (top << 32) | bot
-    return result
-
-
-
-
-@njit(numba.uint64(numba.uint64,numba.uint64))
-def murmur_hash64a(key,seed):
-    multiplier = numba.uint64(0xc6a4a7935bd1e995)
-    length     = numba.uint64(8) 
-    rotator    = numba.uint64(47)
-    key        = numba.uint64(key)
-    seed       = numba.uint64(seed)
-
-    hash_value = numba.uint64(seed) ^ wrapping_mul(length,multiplier)
-
-    key  = wrapping_mul(key,multiplier)
-    key ^= key >> rotator
-    key  = wrapping_mul(key,multiplier)
-    hash_value ^= key
-    hash_value  = wrapping_mul(hash_value,multiplier)
-
-    hash_value ^= hash_value >> rotator
-    hash_value  = wrapping_mul(hash_value,multiplier)
-    hash_value ^= hash_value >> rotator
-    return hash_value
-
-@njit(numba.uint64(numba.uint64))
-def int_hash(value):
-    return murmur_hash64a(value,0)
-
-@njit(numba.uint64(numba.uint64,numba.uint64))
-def int_hash_combo(value,seed):
-    return murmur_hash64a(value,seed)
-
+#! Revise - make rng state per-particle
 @njit
 def rng_skip_ahead_(n, mcdc):
     seed_base = mcdc["rng_seed_base"]
@@ -202,44 +124,48 @@ def rng_skip_ahead_(n, mcdc):
 
     mcdc["rng_seed"] = (g_new * int(seed_base) + c_new) & mod_mask
 
+
+
+
+
+#! Revise - make rng state per-particle
+#! Revise - we really should not be casting everything
+#- to integers each time this is called, which could have
+# - non-negligable performance overhead. Since they should
+#- already be integers anyway, we could just make sure they
+#- are always initialized as ints in the first place.
 @njit
-def stateful_rng(state,mcdc):
-    seed = int(state["rng_seed"])
+def local_rng(P,mcdc):
+    seed = int(P["rng_seed"])
     g = int(mcdc["setting"]["rng_g"])
     c = int(mcdc["setting"]["rng_c"])
     mod = int(mcdc["setting"]["rng_mod"])
     mod_mask = int(mod - 1)
 
-    state["rng_seed"] = (g * seed + c) & mod_mask
-    result =  state["rng_seed"] / mod
+    P["rng_seed"] = (g * seed + c) & mod_mask
+    result =  P["rng_seed"] / mod
     return result
 
-@njit
-def cycle_seed(mcdc):
-    return  int_hash_combo(mcdc["cycle_index"],mcdc["rng_seed"])
 
-@njit
-def pct_seed(cycle_seed):
-    return  int_hash_combo(-1,cycle_seed)
 
-@njit
-def source_seed(source_idx,cycle_seed):
-    return  int_hash_combo(source_idx,cycle_seed)
 
-@njit
-def source_particle_seed(particle_idx,source_seed):
-    return  int_hash_combo(particle_idx,source_seed)
 
 
+#! Revise - we really should not be casting everything
+#- to integers each time this is called, which could have
+# - non-negligable performance overhead. Since they should
+#- already be integers anyway, we could just make sure they
+#- are always initialized as ints in the first place.
 @njit
-def stateless_rng(seed,mcdc):
+def global_rng(mcdc):
+    seed = int(mcdc["rng_seed"])
     g = int(mcdc["setting"]["rng_g"])
     c = int(mcdc["setting"]["rng_c"])
     mod = int(mcdc["setting"]["rng_mod"])
     mod_mask = int(mod - 1)
 
-    seed = (g * int(seed) + c) & mod_mask
-    return seed / mod
+    mcdc["rng_seed"] = (g * int(seed) + c) & mod_mask
+    return mcdc["rng_seed"] / mod
 
 
 # =============================================================================
@@ -248,9 +174,7 @@ def stateless_rng(seed,mcdc):
 
 
 @njit
-def source_particle(source, seed, mcdc):
-    P = np.zeros(1, dtype=type_.particle_record)[0]
-    P["rng_seed"] = seed
+def source_particle(P, source, mcdc):
 
     # Position
     if source["box"]:
@@ -278,7 +202,7 @@ def source_particle(source, seed, mcdc):
     g = sample_discrete(source["group"], P, mcdc)
     t = sample_uniform(source["time"][0], source["time"][1], P, mcdc)
 
-    # Make and return particle
+    # Fill in the remaining fields and return particle
     P["x"] = x
     P["y"] = y
     P["z"] = z
@@ -291,7 +215,6 @@ def source_particle(source, seed, mcdc):
 
     P["sensitivity_ID"] = 0
 
-    return P
 
 
 # =============================================================================
@@ -315,6 +238,7 @@ def add_particle(P, bank):
 
 @njit
 def get_particle(bank, mcdc):
+
     # Check if bank is empty
     if bank["size"] == 0:
         with objmode():
@@ -324,19 +248,20 @@ def get_particle(bank, mcdc):
     bank["size"] -= 1
 
     # Create in-flight particle
-    P = np.zeros(1, dtype=type_.particle)[0]
+    #P = np.zeros(1, dtype=type_.particle)[0]
+    P = adapt.local_particle()
 
     # Set attribute
     P_rec = bank["particles"][bank["size"]]
-    P["x"] = P_rec["x"]
-    P["y"] = P_rec["y"]
-    P["z"] = P_rec["z"]
-    P["t"] = P_rec["t"]
+    P["x"]  = P_rec["x"]
+    P["y"]  = P_rec["y"]
+    P["z"]  = P_rec["z"]
+    P["t"]  = P_rec["t"]
     P["ux"] = P_rec["ux"]
     P["uy"] = P_rec["uy"]
     P["uz"] = P_rec["uz"]
-    P["g"] = P_rec["g"]
-    P["w"] = P_rec["w"]
+    P["g"]  = P_rec["g"]
+    P["w"]  = P_rec["w"]
     P["rng_seed"] = P_rec["rng_seed"]
 
     if mcdc["technique"]["iQMC"]:
@@ -353,6 +278,10 @@ def get_particle(bank, mcdc):
     return P
 
 
+#! Don't worry about this
+#? May run normalize weight
+#? Always zeros the census bank, and either transfers the original content
+#- to the source bank or runs population_control
 @njit
 def manage_particle_banks(mcdc):
     # Record time
@@ -392,6 +321,7 @@ def manage_particle_banks(mcdc):
         mcdc["runtime_bank_management"] += time_end - time_start
 
 
+#! Don't worry about this
 @njit
 def manage_IC_bank(mcdc):
     # Buffer bank
@@ -539,6 +469,7 @@ def total_weight(bank):
     return buff[0]
 
 
+#! Don't worry about this
 @njit
 def bank_rebalance(mcdc):
     # Scan the bank
@@ -656,8 +587,9 @@ def distribute_work(N, mcdc, precursor=False):
 
 
 @njit
-def bank_IC(P, mcdc):
+def bank_IC(P, prog):
     # TODO: Consider multi-nuclide material
+    mcdc = adapt.device(prog)
     material = mcdc["nuclides"][P["material_ID"]]
 
     # =========================================================================
@@ -687,15 +619,21 @@ def bank_IC(P, mcdc):
             print_error("Pn > 1.0.")
 
     # Sample particle
-    if stateful_rng(P,mcdc) < Pn:
-        P_new = split_particle(P,1,mcdc)
+    if local_rng(P,mcdc) < Pn:
+        P_new = copy_particle(P)
         P_new["w"] = 1.0
         P_new["t"] = 0.0
-        add_particle(P_new, mcdc["technique"]["IC_bank_neutron_local"])
+        #! Will need to be refactored for GPU
+        #add_particle(P_new, mcdc["technique"]["IC_bank_neutron_local"])
+        adapt.add_IC(prog,P_new)
 
         # Accumulate fission
         SigmaF = material["fission"][g]
-        mcdc["technique"]["IC_fission_score"] += v * SigmaF
+        
+        #mcdc["technique"]["IC_fission_score"] += v * SigmaF
+        
+        #! Refactored for adapt.global_add
+        adapt.global_add(mcdc["technique"]["IC_fission_score"],0,v * SigmaF)
 
     # =========================================================================
     # Precursor
@@ -733,7 +671,7 @@ def bank_IC(P, mcdc):
             print_error("Pp > 1.0.")
 
     # Sample precursor
-    if stateful_rng(P,mcdc) < Pp:
+    if local_rng(P,mcdc) < Pp:
         idx = mcdc["technique"]["IC_bank_precursor_local"]["size"]
         precursor = mcdc["technique"]["IC_bank_precursor_local"]["precursors"][idx]
         precursor["x"] = P["x"]
@@ -743,7 +681,7 @@ def bank_IC(P, mcdc):
         mcdc["technique"]["IC_bank_precursor_local"]["size"] += 1
 
         # Sample group
-        xi = stateful_rng(P,mcdc) * total
+        xi = local_rng(P,mcdc) * total
         total = 0.0
         for j in range(J):
             total += nu_d[j] / decay[j]
@@ -763,6 +701,7 @@ def bank_IC(P, mcdc):
 #       required due to pure-Python behavior of taking things by reference.
 
 
+#! Don't worry about this
 @njit
 def population_control(mcdc):
     if mcdc["technique"]["pct"] == PCT_COMBING:
@@ -772,7 +711,7 @@ def population_control(mcdc):
         pct_combing_weight(mcdc)
         rng_rebase(mcdc)
 
-
+#! Don't worry about this
 @njit
 def pct_combing(mcdc):
     bank_census = mcdc["bank_census"]
@@ -790,8 +729,7 @@ def pct_combing(mcdc):
     mcdc["technique"]["pc_factor"] *= td
 
     # Tooth offset
-    cyc_seed = cycle_seed(mcdc)
-    xi = stateless_rng(pct_seed(cyc_seed),mcdc)
+    xi = global_rng(mcdc)
     offset = xi * td
 
     # First hiting tooth
@@ -806,12 +744,12 @@ def pct_combing(mcdc):
         tooth = i * td + offset
         idx = math.floor(tooth) - idx_start
         P = copy_particle(bank_census["particles"][idx])
-        #! P = split_particle(bank_census["particles"][idx])
         # Set weight
         P["w"] *= td
         add_particle(P, bank_source)
 
 
+#! Don't worry about this
 @njit
 def pct_combing_weight(mcdc):
     bank_census = mcdc["bank_census"]
@@ -829,8 +767,7 @@ def pct_combing_weight(mcdc):
     mcdc["technique"]["pc_factor"] *= td
 
     # Tooth offset
-    cyc_seed = cycle_seed(mcdc)
-    xi = stateless_rng(pct_seed(cyc_seed),mcdc)
+    xi = global_rng(mcdc)
     offset = xi * td
 
     # First hiting tooth
@@ -846,7 +783,6 @@ def pct_combing_weight(mcdc):
         tooth = i * td + offset
         idx += binary_search(tooth, w_cdf[idx:])
         P = copy_particle(bank_census["particles"][idx])
-        #! P = split_particle(bank_census["particles"][idx])
         # Set weight
         P["w"] = td
         add_particle(P, bank_source)
@@ -895,7 +831,7 @@ def get_particle_cell(P, universe_ID, trans, mcdc):
             return cell["ID"]
 
     # Particle is not found
-    print("A particle is lost at (", P["x"], P["y"], P["z"], ")")
+    #!! print("A particle is lost at (", P["x"], P["y"], P["z"], ")")
     P["alive"] = False
     return -1
 
@@ -946,7 +882,8 @@ def get_particle_speed(P, mcdc):
 
 @njit
 def copy_particle(P):
-    P_new = np.zeros(1, dtype=type_.particle_record)[0]
+    #P_new = np.zeros(1, dtype=type_.particle_record)[0]
+    P_new = adapt.local_particle_record()
     P_new["x"] = P["x"]
     P_new["y"] = P["y"]
     P_new["z"] = P["z"]
@@ -961,15 +898,6 @@ def copy_particle(P):
     return P_new
 
 
-@njit
-def split_particle(P,offset,mcdc):
-    P_new = copy_particle(P)
-    P_new["rng_seed"] = int_hash(P["rng_seed"])
-    #print(P["rng_seed"]," -> ",P_new["rng_seed"])
-    stateful_rng(P,mcdc)
-    return P_new
-
-
 # =============================================================================
 # Cell operations
 # =============================================================================
@@ -1500,14 +1428,19 @@ def score_crossing_t(P, t, x, y, z, mcdc):
 
 @njit
 def score_flux(s, g, t, x, y, z, mu, azi, flux, score):
-    score["bin"][s, g, t, x, y, z, mu, azi] += flux
+    #score["bin"][s, g, t, x, y, z, mu, azi] += flux
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, mu, azi),flux)
+
 
 
 @njit
 def score_current(s, g, t, x, y, z, flux, P, score):
-    score["bin"][s, g, t, x, y, z, 0] += flux * P["ux"]
-    score["bin"][s, g, t, x, y, z, 1] += flux * P["uy"]
-    score["bin"][s, g, t, x, y, z, 2] += flux * P["uz"]
+    #score["bin"][s, g, t, x, y, z, 0] += flux * P["ux"]
+    #score["bin"][s, g, t, x, y, z, 1] += flux * P["uy"]
+    #score["bin"][s, g, t, x, y, z, 2] += flux * P["uz"]
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 0),flux * P["ux"])
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 1),flux * P["uy"])
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 2),flux * P["uz"])
 
 
 @njit
@@ -1515,14 +1448,22 @@ def score_eddington(s, g, t, x, y, z, flux, P, score):
     ux = P["ux"]
     uy = P["uy"]
     uz = P["uz"]
-    score["bin"][s, g, t, x, y, z, 0] += flux * ux * ux
-    score["bin"][s, g, t, x, y, z, 1] += flux * ux * uy
-    score["bin"][s, g, t, x, y, z, 2] += flux * ux * uz
-    score["bin"][s, g, t, x, y, z, 3] += flux * uy * uy
-    score["bin"][s, g, t, x, y, z, 4] += flux * uy * uz
-    score["bin"][s, g, t, x, y, z, 5] += flux * uz * uz
-
-
+    #score["bin"][s, g, t, x, y, z, 0] += flux * ux * ux
+    #score["bin"][s, g, t, x, y, z, 1] += flux * ux * uy
+    #score["bin"][s, g, t, x, y, z, 2] += flux * ux * uz
+    #score["bin"][s, g, t, x, y, z, 3] += flux * uy * uy
+    #score["bin"][s, g, t, x, y, z, 4] += flux * uy * uz
+    #score["bin"][s, g, t, x, y, z, 5] += flux * uz * uz
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 0),flux * ux * ux)
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 1),flux * ux * uy)
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 2),flux * ux * uz)
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 3),flux * uy * uy)
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 4),flux * uy * uz)
+    adapt.global_add(score["bin"],(s, g, t, x, y, z, 5),flux * uz * uz)
+
+
+#! Don't worry about this
+# Cannot be called on the GPU without significant refactoring
 @njit
 def score_closeout_history(score, mcdc):
     # Normalize if eigenvalue mode
@@ -1543,6 +1484,8 @@ def score_closeout_history(score, mcdc):
     score["bin"].fill(0.0)
 
 
+#! Don't worry about this
+# Cannot be called on the GPU without significant refactoring
 @njit
 def score_closeout(score, mcdc):
     N_history = mcdc["setting"]["N_particle"]
@@ -1605,13 +1548,20 @@ def eigenvalue_tally(P, distance, mcdc):
     nuSigmaF = nu * SigmaF
 
     # Fission production (needed even during inactive cycle)
-    mcdc["eigenvalue_tally_nuSigmaF"] += flux * nuSigmaF
+    #mcdc["eigenvalue_tally_nuSigmaF"] += flux * nuSigmaF
+
+    #! Requires refactor of eigenvalue_tally_nuSigmaF to an array
+    adapt.global_add(mcdc["eigenvalue_tally_nuSigmaF"], 0, flux * nuSigmaF)
 
     if mcdc["cycle_active"]:
         # Neutron density
         v = get_particle_speed(P, mcdc)
         n_density = flux / v
-        mcdc["eigenvalue_tally_n"] += n_density
+        #mcdc["eigenvalue_tally_n"] += n_density
+
+        #! Requires refactor of eigenvalue_tally_n to an array
+        adapt.global_add(mcdc["eigenvalue_tally_n"], 0, n_density)
+
         # Maximum neutron density
         if mcdc["n_max"] < n_density:
             mcdc["n_max"] = n_density
@@ -1624,7 +1574,12 @@ def eigenvalue_tally(P, distance, mcdc):
         for j in range(J):
             total += nu_d[j] / decay[j]
         C_density = flux * total * SigmaF / mcdc["k_eff"]
-        mcdc["eigenvalue_tally_C"] += C_density
+
+        #mcdc["eigenvalue_tally_C"] += C_density
+
+        #! Requires refactor of eigenvalue_tally_n to an array
+        adapt.global_add(mcdc["eigenvalue_tally_C"],0,C_density)
+
         # Maximum precursor density
         if mcdc["C_max"] < C_density:
             mcdc["C_max"] = C_density
@@ -1637,28 +1592,28 @@ def eigenvalue_tally_closeout_history(mcdc):
     i_cycle = mcdc["i_cycle"]
 
     # MPI Allreduce
-    buff_nuSigmaF = np.zeros(1, np.float64)
-    buff_n = np.zeros(1, np.float64)
-    buff_nmax = np.zeros(1, np.float64)
-    buff_C = np.zeros(1, np.float64)
-    buff_Cmax = np.zeros(1, np.float64)
+    buff_nuSigmaF  = np.zeros(1, np.float64)
+    buff_n         = np.zeros(1, np.float64)
+    buff_nmax      = np.zeros(1, np.float64)
+    buff_C         = np.zeros(1, np.float64)
+    buff_Cmax      = np.zeros(1, np.float64)
     buff_IC_fission = np.zeros(1, np.float64)
     with objmode():
         MPI.COMM_WORLD.Allreduce(
-            np.array([mcdc["eigenvalue_tally_nuSigmaF"]]), buff_nuSigmaF, MPI.SUM
+            np.array(mcdc["eigenvalue_tally_nuSigmaF"]), buff_nuSigmaF, MPI.SUM
         )
         if mcdc["cycle_active"]:
             MPI.COMM_WORLD.Allreduce(
-                np.array([mcdc["eigenvalue_tally_n"]]), buff_n, MPI.SUM
+                np.array(mcdc["eigenvalue_tally_n"]), buff_n, MPI.SUM
             )
             MPI.COMM_WORLD.Allreduce(np.array([mcdc["n_max"]]), buff_nmax, MPI.MAX)
             MPI.COMM_WORLD.Allreduce(
-                np.array([mcdc["eigenvalue_tally_C"]]), buff_C, MPI.SUM
+                np.array(mcdc["eigenvalue_tally_C"]), buff_C, MPI.SUM
             )
             MPI.COMM_WORLD.Allreduce(np.array([mcdc["C_max"]]), buff_Cmax, MPI.MAX)
             if mcdc["technique"]["IC_generator"]:
                 MPI.COMM_WORLD.Allreduce(
-                    np.array([mcdc["technique"]["IC_fission_score"]]),
+                    np.array(mcdc["technique"]["IC_fission_score"]),
                     buff_IC_fission,
                     MPI.SUM,
                 )
@@ -1698,10 +1653,10 @@ def eigenvalue_tally_closeout_history(mcdc):
             mcdc["technique"]["IC_fission"] += tally_IC_fission
 
     # Reset accumulators
-    mcdc["eigenvalue_tally_nuSigmaF"] = 0.0
-    mcdc["eigenvalue_tally_n"] = 0.0
-    mcdc["eigenvalue_tally_C"] = 0.0
-    mcdc["technique"]["IC_fission_score"] = 0.0
+    mcdc["eigenvalue_tally_nuSigmaF"][0] = 0.0
+    mcdc["eigenvalue_tally_n"][0] = 0.0
+    mcdc["eigenvalue_tally_C"][0] = 0.0
+    mcdc["technique"]["IC_fission_score"][0] = 0.0
 
     # =====================================================================
     # Gyration radius
@@ -1860,6 +1815,7 @@ def move_to_event(P, mcdc):
         material = mcdc["materials"][P["material_ID"]]
         w = P["iqmc_w"]
         SigmaT = material["total"][:]
+        #! Modifies global data:  mcdc["technique"]["iqmc_flux"][:, t, x, y, z] += flux
         score_iqmc_flux(P, distance, mcdc)
         w_final = continuous_weight_reduction(w, distance, SigmaT)
         P["iqmc_w"] = w_final
@@ -1867,8 +1823,10 @@ def move_to_event(P, mcdc):
 
     # Score tracklength tallies
     if mcdc["tally"]["tracklength"] and mcdc["cycle_active"]:
+        #! Modifies global data: loads of accumulations
         score_tracklength(P, distance, mcdc)
     if mcdc["setting"]["mode_eigenvalue"]:
+        #! Modifies global data: some accumulations and a maximum
         eigenvalue_tally(P, distance, mcdc)
 
     # Move particle
@@ -1886,7 +1844,10 @@ def distance_to_collision(P, mcdc):
         return INF
 
     # Sample collision distance
-    xi = stateful_rng(P,mcdc)
+    xi = local_rng(P,mcdc)
+
+    #! BUGFIX REQUIRED: There is a small (but non-zero) chance
+    #- that `xi` is zero, making this log unhappy
     distance = -math.log(xi) / SigmaT
     return distance
 
@@ -2025,7 +1986,8 @@ def distance_to_mesh(P, mesh, mcdc):
 
 
 @njit
-def surface_crossing(P, mcdc):
+def surface_crossing(P, prog):
+    mcdc = adapt.device(prog)
     trans = P["translation"]
 
     # Implement BC
@@ -2046,15 +2008,10 @@ def surface_crossing(P, mcdc):
             P["cell_ID"] = get_particle_cell(P, 0, trans, mcdc)
 
     # Sensitivity quantification for surface?
-    if surface["sensitivity"] and (
-        P["sensitivity_ID"] == 0
-        or mcdc["technique"]["dsm_order"] == 2
-        and P["sensitivity_ID"] <= mcdc["setting"]["N_sensitivity"]
-    ):
+    if surface["sensitivity"] and P["sensitivity_ID"] == 0:
         material_ID_new = get_particle_material(P, mcdc)
         if material_ID_old != material_ID_new:
-            # Sample derivative source particles
-            sensitivity_surface(P, surface, material_ID_old, material_ID_new, mcdc)
+            sensitivity_surface(P, surface, material_ID_old, material_ID_new, prog)
 
 
 # =============================================================================
@@ -2103,7 +2060,7 @@ def collision(P, mcdc):
         SigmaT -= SigmaC
 
     # Sample collision type
-    xi = stateful_rng(P,mcdc) * SigmaT
+    xi = local_rng(P,mcdc) * SigmaT
     tot = SigmaS
     if tot > xi:
         event = EVENT_SCATTERING
@@ -2122,7 +2079,7 @@ def collision(P, mcdc):
 
 
 @njit
-def capture(P, mcdc):
+def capture(P, prog):
     # Kill the current particle
     P["alive"] = False
 
@@ -2133,7 +2090,8 @@ def capture(P, mcdc):
 
 
 @njit
-def scattering(P, mcdc):
+def scattering(P, prog):
+    mcdc = adapt.device(prog)
     # Kill the current particle
     P["alive"] = False
 
@@ -2151,21 +2109,27 @@ def scattering(P, mcdc):
     nu_s = material["nu_s"][g]
 
     # Get number of secondaries
-    N = int(math.floor(weight_eff * nu_s + stateful_rng(P,mcdc)))
+    N = int(math.floor(weight_eff * nu_s + local_rng(P,mcdc)))
 
     for n in range(N):
         # Create new particle
         #P_new = np.zeros(1, dtype=type_.particle_record)[0]
-        P_new = split_particle(P,n,mcdc)
+        P_new = adapt.local_particle_record()
 
         # Set weight
         P_new["w"] = weight_new
+        #! Offset seed by multiple of large prime to try to get rid
+        #- of any correlation between rng sequences of siblings.
+        #- If this does not work, some more agressive hashing may be
+        #- required.
+        P_new["rng_seed"] = P["rng_seed"] + n * 2147483647
 
         # Sample scattering phase space
         sample_phasespace_scattering(P, material, P_new, mcdc)
 
         # Bank
-        add_particle(P_new, mcdc["bank_active"])
+        #add_particle(P_new, mcdc["bank_active"])
+        adapt.add_active(prog,P_new)
 
 
 @njit
@@ -2183,7 +2147,7 @@ def sample_phasespace_scattering(P, material, P_new, mcdc):
     P_new["sensitivity_ID"] = P["sensitivity_ID"]
 
     # Sample outgoing energy
-    xi = stateful_rng(P_new,mcdc)
+    xi = local_rng(P,mcdc)
     tot = 0.0
     for g_out in range(G):
         tot += chi_s[g_out]
@@ -2192,10 +2156,10 @@ def sample_phasespace_scattering(P, material, P_new, mcdc):
     P_new["g"] = g_out
 
     # Sample scattering angle
-    mu = 2.0 * stateful_rng(P_new,mcdc) - 1.0
+    mu = 2.0 * local_rng(P,mcdc) - 1.0
 
     # Sample azimuthal direction
-    azi = 2.0 * PI * stateful_rng(P_new,mcdc)
+    azi = 2.0 * PI * local_rng(P,mcdc)
     cos_azi = math.cos(azi)
     sin_azi = math.sin(azi)
     Ac = (1.0 - mu**2) ** 0.5
@@ -2228,7 +2192,10 @@ def sample_phasespace_scattering(P, material, P_new, mcdc):
 
 
 @njit
-def fission(P, mcdc):
+def fission(P, prog):
+
+    mcdc = adapt.device(prog)
+
     # Kill the current particle
     P["alive"] = False
 
@@ -2246,15 +2213,20 @@ def fission(P, mcdc):
         weight_new = P["w"]
 
     # Get number of secondaries
-    N = int(math.floor(weight_eff * nu / mcdc["k_eff"] + stateful_rng(P,mcdc)))
+    N = int(math.floor(weight_eff * nu / mcdc["k_eff"] + local_rng(P,mcdc)))
 
     for n in range(N):
         # Create new particle
         #P_new = np.zeros(1, dtype=type_.particle_record)[0]
-        P_new = split_particle(P,n,mcdc)
+        P_new = adapt.local_particle_record()
 
         # Set weight
         P_new["w"] = weight_new
+        #! Offset seed by multiple of large prime to try to get rid
+        #- of any correlation between rng sequences of siblings.
+        #- If this does not work, some more agressive hashing may be
+        #- required.
+        P_new["rng_seed"] = P["rng_seed"] + n * 524287
 
         # Sample scattering phase space
         sample_phasespace_fission(P, material, P_new, mcdc)
@@ -2265,9 +2237,11 @@ def fission(P, mcdc):
 
         # Bank
         if mcdc["setting"]["mode_eigenvalue"]:
-            add_particle(P_new, mcdc["bank_census"])
+            #add_particle(P_new, mcdc["bank_census"])
+            adapt.add_census(prog,P_new)
         else:
-            add_particle(P_new, mcdc["bank_active"])
+            #add_particle(P_new, mcdc["bank_active"])
+            adapt.add_active(prog,P_new)
 
 
 @njit
@@ -2289,10 +2263,10 @@ def sample_phasespace_fission(P, material, P_new, mcdc):
     P_new["sensitivity_ID"] = P["sensitivity_ID"]
 
     # Sample isotropic direction
-    P_new["ux"], P_new["uy"], P_new["uz"] = sample_isotropic_direction(P_new, mcdc)
+    P_new["ux"], P_new["uy"], P_new["uz"] = sample_isotropic_direction(P, mcdc)
 
     # Prompt or delayed?
-    xi = stateful_rng(P_new,mcdc) * nu
+    xi = local_rng(P,mcdc) * nu
     tot = nu_p
     if xi < tot:
         prompt = True
@@ -2312,7 +2286,7 @@ def sample_phasespace_fission(P, material, P_new, mcdc):
                     decay = nuclide["decay"][j]
                     break
                 SigmaF = material["fission"][g]
-                xi = stateful_rng(P_new,mcdc) * nu_d[j] * SigmaF
+                xi = local_rng(P,mcdc) * nu_d[j] * SigmaF
                 tot = 0.0
                 for i in range(N_nuclide):
                     nuclide = mcdc["nuclides"][material["nuclide_IDs"][i]]
@@ -2326,7 +2300,7 @@ def sample_phasespace_fission(P, material, P_new, mcdc):
                 break
 
     # Sample outgoing energy
-    xi = stateful_rng(P_new,mcdc)
+    xi = local_rng(P,mcdc)
     tot = 0.0
     for g_out in range(G):
         tot += spectrum[g_out]
@@ -2336,7 +2310,7 @@ def sample_phasespace_fission(P, material, P_new, mcdc):
 
     # Sample emission time
     if not prompt:
-        xi = stateful_rng(P_new,mcdc)
+        xi = local_rng(P,mcdc)
         P_new["t"] -= math.log(xi) / decay
 
 
@@ -2359,10 +2333,10 @@ def sample_phasespace_fission_nuclide(P, nuclide, P_new, mcdc):
     P_new["sensitivity_ID"] = P["sensitivity_ID"]
 
     # Sample isotropic direction
-    P_new["ux"], P_new["uy"], P_new["uz"] = sample_isotropic_direction(P_new, mcdc)
+    P_new["ux"], P_new["uy"], P_new["uz"] = sample_isotropic_direction(P, mcdc)
 
     # Prompt or delayed?
-    xi = stateful_rng(P_new,mcdc) * nu
+    xi = local_rng(P,mcdc) * nu
     tot = nu_p
     if xi < tot:
         prompt = True
@@ -2379,7 +2353,7 @@ def sample_phasespace_fission_nuclide(P, nuclide, P_new, mcdc):
                 break
 
     # Sample outgoing energy
-    xi = stateful_rng(P_new,mcdc)
+    xi = local_rng(P,mcdc)
     tot = 0.0
     for g_out in range(G):
         tot += spectrum[g_out]
@@ -2389,7 +2363,7 @@ def sample_phasespace_fission_nuclide(P, nuclide, P_new, mcdc):
 
     # Sample emission time
     if not prompt:
-        xi = stateful_rng(P_new,mcdc)
+        xi = local_rng(P,mcdc)
         P_new["t"] -= math.log(xi) / decay
 
 
@@ -2426,11 +2400,11 @@ def branchless_collision(P, mcdc):
     # Set spectrum and decay rate
     fission = True
     prompt = True
-    if stateful_rng(P,mcdc) < n_scatter / n_total:
+    if local_rng(P,mcdc) < n_scatter / n_total:
         fission = False
         spectrum = material["chi_s"][g]
     else:
-        xi = stateful_rng(P,mcdc) * nu
+        xi = local_rng(P,mcdc) * nu
         tot = nu_p
         if xi < tot:
             spectrum = material["chi_p"][g]
@@ -2445,7 +2419,7 @@ def branchless_collision(P, mcdc):
 
     # Set time
     if not prompt:
-        xi = stateful_rng(P,mcdc)
+        xi = local_rng(P,mcdc)
         P["t"] -= math.log(xi) / decay
 
         # Kill if it's beyond time boundary
@@ -2454,7 +2428,7 @@ def branchless_collision(P, mcdc):
             return
 
     # Set energy
-    xi = stateful_rng(P,mcdc)
+    xi = local_rng(P,mcdc)
     tot = 0.0
     for g_out in range(G):
         tot += spectrum[g_out]
@@ -2482,7 +2456,9 @@ def time_boundary(P, mcdc):
 
 
 @njit
-def weight_window(P, mcdc):
+def weight_window(P, prog):
+    mcdc = adapt.device(prog)
+
     # Get indices
     t, x, y, z, outside = mesh_get_index(P, mcdc["technique"]["ww_mesh"])
 
@@ -2506,18 +2482,20 @@ def weight_window(P, mcdc):
         # Splitting (keep the original particle)
         n_split = math.floor(p)
         for i in range(n_split - 1):
-            add_particle(split_particle(P,i,mcdc), mcdc["bank_active"])
+            #add_particle(copy_particle(P), mcdc["bank_active"])
+            adapt.add_active(prog,P)
 
         # Russian roulette
         p -= n_split
-        xi = stateful_rng(P,mcdc)
+        xi = local_rng(P,mcdc)
         if xi <= p:
-            add_particle(split_particle(P,-1,mcdc), mcdc["bank_active"])
+            #add_particle(copy_particle(P), mcdc["bank_active"])
+            adapt.add_active(prog,P)
 
     # Below target
     elif p < 1.0 / width:
         # Russian roulette
-        xi = stateful_rng(P,mcdc)
+        xi = local_rng(P,mcdc)
         if xi > p:
             P["alive"] = False
         else:
@@ -2667,12 +2645,14 @@ def prepare_qmc_fission_source(mcdc):
 
 
 @njit
-def prepare_qmc_particles(mcdc):
+def prepare_qmc_particles(prog):
     """
     Create N_particles assigning the position, direction, and group from the
     QMC Low-Discrepency Sequence. Particles are added to the bank_source.
 
     """
+    mcdc = adapt.device(prog)
+
     # determine which portion of particles to loop through
     N_particle = mcdc["setting"]["N_particle"]
     N_work = mcdc["mpi_work_size"]
@@ -2700,9 +2680,8 @@ def prepare_qmc_particles(mcdc):
 
     for n in range(start, stop):
         # Create new particle
-        P_new = np.zeros(1, dtype=type_.particle_record)[0]
-        P_new["rng_seed"] = spawn_seed(n,mcdc)
-        #P_new = split_particle(P,n,mcdc)
+        #P_new = np.zeros(1, dtype=type_.particle_record)[0]
+        P_new = adapt.local_particle_record()
         # assign direction
         P_new["x"] = sample_qmc_position(xa, xb, lds[n, 0])
         P_new["y"] = sample_qmc_position(ya, yb, lds[n, 4])
@@ -2724,8 +2703,11 @@ def prepare_qmc_particles(mcdc):
         # Set weight
         P_new["iqmc_w"] = Q[:, t, x, y, z] * dV * Nt / N_particle
         P_new["w"] = (P_new["iqmc_w"]).sum()
+        #! Set per-particle seed
+        P_new["rng_seed"]
         # add to source bank
-        add_particle(P_new, mcdc["bank_source"])
+        #add_particle(P_new, mcdc["bank_source"])
+        adapt.add_source(prog,P_new)
 
 
 @njit
@@ -2975,7 +2957,8 @@ def generate_iqmc_material_idx(mcdc):
     # variables for cell finding functions
     trans = np.zeros((3,))
     # create particle to utilize cell finding functions
-    P_temp = np.zeros(1, dtype=type_.particle)[0]
+    #P_temp = np.zeros(1, dtype=type_.particle)[0]
+    P_temp = adapt.local_particle()
     # set default attributes
     P_temp["alive"] = True
     P_temp["material_ID"] = -1
@@ -3074,10 +3057,11 @@ def modified_gram_schmidt(V, u):
 
 
 @njit
-def AxV(phi, b, mcdc):
+def AxV(phi, b, prog):
     """
     Linear operator to be used with GMRES.
     """
+    mcdc = adapt.device(prog)
     matrix_shape = mcdc["technique"]["iqmc_flux"].shape
     vector_size = mcdc["technique"]["iqmc_flux"].size
 
@@ -3089,7 +3073,7 @@ def AxV(phi, b, mcdc):
 
     # QMC Sweep
     prepare_qmc_source(mcdc)
-    prepare_qmc_particles(mcdc)
+    prepare_qmc_particles(prog)
     mcdc["technique"]["iqmc_flux"] = np.zeros_like(mcdc["technique"]["iqmc_flux"])
     loop_source(mcdc)
     # sum resultant flux on all processors
@@ -3102,11 +3086,12 @@ def AxV(phi, b, mcdc):
 
 
 @njit
-def RHS(mcdc):
+def RHS(prog):
     """
     We solve A x = b with a Krylov method. This function extracts
     b by doing a transport sweep of the fixed-source.
     """
+    mcdc = adapt.device(prog)
     # reshape v and assign to iqmc_flux
     Nt = mcdc["technique"]["iqmc_flux"].size
     mcdc["technique"]["iqmc_flux"] = np.zeros_like(mcdc["technique"]["iqmc_flux"])
@@ -3117,7 +3102,7 @@ def RHS(mcdc):
 
     # QMC Sweep
     prepare_qmc_source(mcdc)
-    prepare_qmc_particles(mcdc)
+    prepare_qmc_particles(prog)
     mcdc["technique"]["iqmc_flux"] = np.zeros_like(mcdc["technique"]["iqmc_flux"])
     loop_source(mcdc)
     # sum resultant flux on all processors
@@ -3129,11 +3114,12 @@ def RHS(mcdc):
 
 
 @njit
-def HxV(V, mcdc):
+def HxV(V, prog):
     """
     Linear operator for Davidson method,
     scattering + streaming terms -> (I-L^(-1)S)*phi
     """
+    mcdc = adapt.device(prog)
     # flux input is most recent iteration of eigenvector
     v = V[:, -1]
     # reshape v and assign to iqmc_flux
@@ -3146,7 +3132,7 @@ def HxV(V, mcdc):
 
     # QMC Sweep
     prepare_qmc_scattering_source(mcdc)
-    prepare_qmc_particles(mcdc)
+    prepare_qmc_particles(prog)
     mcdc["technique"]["iqmc_flux"] = np.zeros_like(mcdc["technique"]["iqmc_flux"])
     loop_source(mcdc)
     # sum resultant flux on all processors
@@ -3160,11 +3146,12 @@ def HxV(V, mcdc):
 
 
 @njit
-def FxV(V, mcdc):
+def FxV(V, prog):
     """
     Linear operator for Davidson method,
     fission term -> (L^(-1)F*phi)
     """
+    mcdc = adapt.device(prog)
     # flux input is most recent iteration of eigenvector
     v = V[:, -1]
     # reshape v and assign to iqmc_flux
@@ -3178,7 +3165,7 @@ def FxV(V, mcdc):
 
     # QMC Sweep
     prepare_qmc_fission_source(mcdc)
-    prepare_qmc_particles(mcdc)
+    prepare_qmc_particles(prog)
     mcdc["technique"]["iqmc_flux"] = np.zeros_like(mcdc["technique"]["iqmc_flux"])
     loop_source(mcdc)
     # sum resultant flux on all processors
@@ -3190,13 +3177,14 @@ def FxV(V, mcdc):
 
 
 @njit
-def preconditioner(V, mcdc, num_sweeps=3):
+def preconditioner(V, prog, num_sweeps=3):
     """
     Linear operator approximation of (I-L^(-1)S)*phi
 
     In this case the preconditioner is a specified number of purely scattering
     transport sweeps.
     """
+    mcdc = adapt.device(prog)
     # flux input is most recent iteration of eigenvector
     v = V[:, -1]
     # reshape v and assign to iqmc_flux
@@ -3213,7 +3201,7 @@ def preconditioner(V, mcdc, num_sweeps=3):
 
         # QMC Sweep
         prepare_qmc_scattering_source(mcdc)
-        prepare_qmc_particles(mcdc)
+        prepare_qmc_particles(prog)
         mcdc["technique"]["iqmc_flux"] = np.zeros_like(mcdc["technique"]["iqmc_flux"])
         loop_source(mcdc)
         # sum resultant flux on all processors
@@ -3249,7 +3237,7 @@ def weight_roulette(P, mcdc):
 
     """
     chance = mcdc["technique"]["wr_chance"]
-    x = stateful_rng(P,mcdc)
+    x = local_rng(P,mcdc)
     if x <= chance:
         P["iqmc_w"] /= chance
         P["w"] /= chance
@@ -3263,25 +3251,14 @@ def weight_roulette(P, mcdc):
 
 
 @njit
-def sensitivity_surface(P, surface, material_ID_old, material_ID_new, mcdc):
-    # Sample number of derivative sources
-    xi = surface["dsm_Np"]
-    if xi != 1.0:
-        Np = int(math.floor(xi + stateful_rng(P,mcdc)))
-    else:
-        Np = 1
+def sensitivity_surface(P, surface, material_ID_old, material_ID_new, prog):
+    # Put the current particle into the secondary bank
+    #add_particle(copy_particle(P), mcdc["bank_active"])
+    mcdc = adapt.device(prog)
+    adapt.add_active(prog,P)
 
-    # Terminate and put the current particle into the secondary bank
-    P["alive"] = False
-    add_particle(copy_particle(P), mcdc["bank_active"])
-    #! add_particle(split_particle(P), mcdc["bank_active"])
-
-    # Get sensitivity ID
-    ID = surface["sensitivity_ID"]
-    if mcdc["technique"]["dsm_order"] == 2:
-        ID1 = min(P["sensitivity_ID"], ID)
-        ID2 = max(P["sensitivity_ID"], ID)
-        ID = get_DSM_ID(ID1, ID2, mcdc["setting"]["N_sensitivity"])
+    # Assign sensitivity_ID
+    P["sensitivity_ID"] = surface["sensitivity_ID"]
 
     # Get materials
     material_old = mcdc["materials"][material_ID_old]
@@ -3289,8 +3266,8 @@ def sensitivity_surface(P, surface, material_ID_old, material_ID_new, mcdc):
 
     # Determine the plus and minus components and then their weight signs
     trans = P["translation"]
-    sign_origin = surface_normal_component(P, surface, trans)
-    if sign_origin > 0.0:
+    sign = surface_evaluate(P, surface, trans)
+    if sign > 0.0:
         # New is +, old is -
         sign_new = -1.0
         sign_old = 1.0
@@ -3310,11 +3287,19 @@ def sensitivity_surface(P, surface, material_ID_old, material_ID_new, mcdc):
     nu_s_new = material_new["nu_s"][g]
     nu_old = material_old["nu_f"][g]
     nu_new = material_new["nu_f"][g]
+
     nuSigmaS_old = nu_s_old * SigmaS_old
     nuSigmaS_new = nu_s_new * SigmaS_new
     nuSigmaF_old = nu_old * SigmaF_old
     nuSigmaF_new = nu_new * SigmaF_new
 
+    # Get inducing flux
+    #   Apply constant flux approximation for tangent direction [Dupree 2002]
+    mu = abs(surface_normal_component(P, surface, trans))
+    if mu < 0.01:
+        mu = 0.01 / 2
+    flux = P["w"] / mu
+
     # Get source type probabilities
     delta = -(SigmaT_old * sign_old + SigmaT_new * sign_new)
     scatter = nuSigmaS_old * sign_old + nuSigmaS_new * sign_new
@@ -3324,186 +3309,57 @@ def sensitivity_surface(P, surface, material_ID_old, material_ID_new, mcdc):
     p_fission = abs(fission)
     p_total = p_delta + p_scatter + p_fission
 
-    # Get inducing flux
-    #   Apply constant flux approximation for tangent direction
-    #   [Dupree 2002, Eq. (7.39)]
-    mu = abs(sign_origin)
-    epsilon = 0.01
-    if mu < epsilon:
-        mu = epsilon / 2
-    flux = P["w"] / mu
-
     # Base weight
-    w_hat = p_total * flux / xi
-
-    # Sample the derivative sources
-    for n in range(Np):
-        # Create new particle
-        P_new = split_particle(P,n,mcdc)
+    w_hat = p_total * flux
 
-        # Sample source type
-        xi = stateful_rng(P,mcdc) * p_total
-        tot = p_delta
+    # Sample source type
+    xi = local_rng(P,mcdc) * p_total
+    tot = p_delta
+    if tot > xi:
+        # Delta source
+        sign_delta = delta / p_delta
+        P["w"] = w_hat * sign_delta
+    else:
+        tot += p_scatter
         if tot > xi:
-            # Delta source
-            sign_delta = delta / p_delta
-            P_new["w"] = w_hat * sign_delta
-        else:
-            tot += p_scatter
-            if tot > xi:
-                # Scattering source
-                total_scatter = nuSigmaS_old + nuSigmaS_new
-                w_s = w_hat * total_scatter / p_scatter
-
-                # Sample if it is from + or - component
-                if nuSigmaS_old > stateful_rng(P, mcdc) * total_scatter:
-                    sample_phasespace_scattering(P, material_old, P_new, mcdc)
-                    P_new["w"] = w_s * sign_old
-                else:
-                    sample_phasespace_scattering(P, material_new, P_new, mcdc)
-                    P_new["w"] = w_s * sign_new
+            # Scattering source
+            total_scatter = nuSigmaS_old + nuSigmaS_new
+            w_hat *= total_scatter / p_scatter
+
+            # Sample if it is from + or - component
+            if nuSigmaS_old > local_rng(P,mcdc) * total_scatter:
+                sample_phasespace_scattering(P, material_old, P, mcdc)
+                P["w"] = w_hat * sign_old
             else:
-                # Fission source
-                total_fission = nuSigmaF_old + nuSigmaF_new
-                w_f = w_hat * total_fission / p_fission
-
-                # Sample if it is from + or - component
-                if nuSigmaF_old > stateful_rng(P,mcdc) * total_fission:
-                    sample_phasespace_fission(P, material_old, P_new, mcdc)
-                    P_new["w"] = w_f * sign_old
-                else:
-                    sample_phasespace_fission(P, material_new, P_new, mcdc)
-                    P_new["w"] = w_f * sign_new
-
-        # Assign sensitivity_ID
-        P_new["sensitivity_ID"] = ID
-
-        # Shift back if needed to ensure crossing
-        sign = surface_normal_component(P_new, surface, trans)
-        if sign_origin * sign > 0.0:
-            # Get surface normal
-            nx, ny, nz = surface_normal(P_new, surface, trans)
-
-            # The shift
-            if sign > 0.0:
-                P_new["x"] -= nx * 2 * SHIFT
-                P_new["y"] -= ny * 2 * SHIFT
-                P_new["z"] -= nz * 2 * SHIFT
+                sample_phasespace_scattering(P, material_new, P, mcdc)
+                P["w"] = w_hat * sign_new
+        else:
+            # Fission source
+            total_fission = nuSigmaF_old + nuSigmaF_new
+            w_hat *= total_fission / p_fission
+
+            # Sample if it is from + or - component
+            if nuSigmaF_old > local_rng(P,mcdc) * total_fission:
+                sample_phasespace_fission(P, material_old, P, mcdc)
+                P["w"] = w_hat * sign_old
             else:
-                P_new["x"] += nx * 2 * SHIFT
-                P_new["y"] += ny * 2 * SHIFT
-                P_new["z"] += nz * 2 * SHIFT
-
-        # Put the current particle into the secondary bank
-        add_particle(P_new, mcdc["bank_active"])
-
-    # Sample potential second-order sensitivity particles?
-    if mcdc["technique"]["dsm_order"] < 2 or P["sensitivity_ID"] > 0:
-        return
-
-    # Get total probability
-    p_total = 0.0
-    for material in [material_new, material_old]:
-        if material["sensitivity"]:
-            N_nuclide = material["N_nuclide"]
-            for i in range(N_nuclide):
-                nuclide = mcdc["nuclides"][material["nuclide_IDs"][i]]
-                if nuclide["sensitivity"]:
-                    sigmaT = nuclide["total"][g]
-                    sigmaS = nuclide["scatter"][g]
-                    sigmaF = nuclide["fission"][g]
-                    nu_s = nuclide["nu_s"][g]
-                    nu = nuclide["nu_f"][g]
-                    nusigmaS = nu_s * sigmaS
-                    nusigmaF = nu * sigmaF
-                    total = sigmaT + nusigmaS + nusigmaF
-                    p_total += total
-
-    # Base weight
-    w = p_total * flux / surface["dsm_Np"]
-
-    # Sample source
-    for n in range(Np):
-        source_obtained = False
-
-        # Create new particle
-        P_new = split_particle(P,n,mcdc)
-
-        # Sample term
-        xi = stateful_rng(P_new,mcdc) * p_total
-        tot = 0.0
-        for material_ID, sign in zip(
-            [material_ID_new, material_ID_old], [sign_new, sign_old]
-        ):
-            material = mcdc["materials"][material_ID]
-            if material["sensitivity"]:
-                N_nuclide = material["N_nuclide"]
-                for i in range(N_nuclide):
-                    nuclide = mcdc["nuclides"][material["nuclide_IDs"][i]]
-                    if nuclide["sensitivity"]:
-                        # Source ID
-                        ID1 = min(nuclide["sensitivity_ID"], surface["sensitivity_ID"])
-                        ID2 = max(nuclide["sensitivity_ID"], surface["sensitivity_ID"])
-                        ID_source = get_DSM_ID(
-                            ID1, ID2, mcdc["setting"]["N_sensitivity"]
-                        )
-
-                        sigmaT = nuclide["total"][g]
-                        sigmaS = nuclide["scatter"][g]
-                        sigmaF = nuclide["fission"][g]
-                        nu_s = nuclide["nu_s"][g]
-                        nu = nuclide["nu_f"][g]
-                        nusigmaS = nu_s * sigmaS
-                        nusigmaF = nu * sigmaF
-
-                        tot += sigmaT
-                        if tot > xi:
-                            # Delta source
-                            P_new["w"] = -w * sign
-                            P_new["sensitivity_ID"] = ID_source
-                            add_particle(P_new, mcdc["bank_active"])
-                            source_obtained = True
-                        else:
-                            P_new["w"] = w * sign
-
-                            tot += nusigmaS
-                            if tot > xi:
-                                # Scattering source
-                                sample_phasespace_scattering(P, nuclide, P_new, mcdc)
-                                P_new["sensitivity_ID"] = ID_source
-                                add_particle(P_new, mcdc["bank_active"])
-                                source_obtained = True
-                            else:
-                                tot += nusigmaF
-                                if tot > xi:
-                                    # Fission source
-                                    sample_phasespace_fission_nuclide(
-                                        P, nuclide, P_new, mcdc
-                                    )
-                                    P_new["sensitivity_ID"] = ID_source
-                                    add_particle(P_new, mcdc["bank_active"])
-                                    source_obtained = True
-                    if source_obtained:
-                        break
-                if source_obtained:
-                    break
+                sample_phasespace_fission(P, material_new, P, mcdc)
+                P["w"] = w_hat * sign_new
 
 
 @njit
 def sensitivity_material(P, mcdc):
-    # The incident particle is already terminated
-
     # Get material
     material = mcdc["materials"][P["material_ID"]]
-
-    # Check if sensitivity nuclide is sampled
     g = P["g"]
     SigmaT = material["total"][g]
+
+    # Check if sensitivity nuclide is sampled
     N_nuclide = material["N_nuclide"]
     if N_nuclide == 1:
         nuclide = mcdc["nuclides"][material["nuclide_IDs"][0]]
     else:
-        xi = stateful_rng(P,mcdc) * SigmaT
+        xi = local_rng(P,mcdc) * SigmaT
         tot = 0.0
         for i in range(N_nuclide):
             nuclide = mcdc["nuclides"][material["nuclide_IDs"][i]]
@@ -3514,73 +3370,44 @@ def sensitivity_material(P, mcdc):
     if not nuclide["sensitivity"]:
         return
 
-    # Sample number of derivative sources
-    xi = nuclide["dsm_Np"]
-    if xi != 1.0:
-        Np = int(math.floor(xi + stateful_rng(P,mcdc)))
-    else:
-        Np = 1
-
-    # Get sensitivity ID
-    ID = nuclide["sensitivity_ID"]
-    double = False
-    if mcdc["technique"]["dsm_order"] == 2:
-        ID1 = min(P["sensitivity_ID"], ID)
-        ID2 = max(P["sensitivity_ID"], ID)
-        ID = get_DSM_ID(ID1, ID2, mcdc["setting"]["N_sensitivity"])
-        if ID1 == ID2:
-            double = True
-
     # Undo implicit capture
     if mcdc["technique"]["implicit_capture"]:
         SigmaC = material["capture"][g]
         P["w"] *= SigmaT / (SigmaT - SigmaC)
 
+    # Revive and assign sensitivity_ID
+    P["alive"] = True
+    P["sensitivity_ID"] = nuclide["sensitivity_ID"]
+
     # Get XS
     g = P["g"]
-    sigmaT = nuclide["total"][g]
-    sigmaS = nuclide["scatter"][g]
-    sigmaF = nuclide["fission"][g]
+    SigmaT = nuclide["total"][g]
+    SigmaS = nuclide["scatter"][g]
+    SigmaF = nuclide["fission"][g]
     nu_s = nuclide["nu_s"][g]
     nu = nuclide["nu_f"][g]
-    nusigmaS = nu_s * sigmaS
-    nusigmaF = nu * sigmaF
-
-    # Base weight
-    total = sigmaT + nusigmaS + nusigmaF
-    w = total * P["w"] / sigmaT / xi
 
-    # Double if it's self-second-order
-    if double:
-        w *= 2
+    nuSigmaS = nu_s * SigmaS
+    nuSigmaF = nu * SigmaF
 
-    # Sample the derivative sources
-    for n in range(Np):
-        # Create new particle
-        P_new = split_particle(P,n,mcdc)
+    # Set weight
+    total = SigmaT + nuSigmaS + nuSigmaF
+    P["w"] = total * P["w"] / SigmaT
 
-        # Sample source type
-        xi = stateful_rng(P_new,mcdc) * total
-        tot = sigmaT
+    # Sample source type
+    xi = local_rng(P,mcdc) * total
+    tot = SigmaT
+    if tot > xi:
+        # Delta source
+        P["w"] *= -1
+    else:
+        tot += nuSigmaS
         if tot > xi:
-            # Delta source
-            P_new["w"] = -w
+            # Scattering source
+            sample_phasespace_scattering(P, nuclide, P, mcdc)
         else:
-            P_new["w"] = w
-
-            tot += nusigmaS
-            if tot > xi:
-                # Scattering source
-                sample_phasespace_scattering(P, nuclide, P_new, mcdc)
-            else:
-                # Fission source
-                sample_phasespace_fission_nuclide(P, nuclide, P_new, mcdc)
-
-        # Assign sensitivity_ID
-        P_new["sensitivity_ID"] = ID
-
-        # Put the current particle into the secondary bank
-        add_particle(P_new, mcdc["bank_active"])
+            # Fission source
+            sample_phasespace_fission_nuclide(P, nuclide, P, mcdc)
 
 
 # ==============================================================================
@@ -3602,29 +3429,6 @@ def track_particle(P, mcdc):
     mcdc["particle_track_N"] += 1
 
 
-# ==============================================================================
-# Derivative Source Method (DSM)
-# ==============================================================================
-
-
-@njit
-def get_DSM_ID(ID1, ID2, Np):
-    # First-order sensitivity
-    if ID1 == 0:
-        return ID2
-
-    # Self second-order
-    if ID1 == ID2:
-        return Np + ID1
-
-    # Cross second-order
-    ID1 -= 1
-    ID2 -= 1
-    return int(
-        2 * Np + (Np * (Np - 1) / 2) - (Np - ID1) * ((Np - ID1) - 1) / 2 + ID2 - ID1
-    )
-
-
 # =============================================================================
 # Miscellany
 # =============================================================================
